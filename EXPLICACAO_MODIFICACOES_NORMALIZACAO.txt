================================================================================
EXPLICA√á√ÉO COMPLETA DAS MODIFICA√á√ïES DE NORMALIZA√á√ÉO - PEAB
Data: 09/12/2025
Atualizado: 09/12/2025 18:30 - GRID SEARCH ADAPTATIVO implementado
================================================================================

‚ö†Ô∏è ALERTA IMPORTANTE - CORRE√á√ïES IMPLEMENTADAS:
   
   CORRE√á√ÉO 1 (09/12 manh√£): Normaliza√ß√£o Sim√©trica
   - ERRADO: Z-score + Scaling (centraliza pela m√©dia)
   - CORRETO: Normaliza√ß√£o por max_abs (preserva zero original)
   
   CORRE√á√ÉO 2 (09/12 tarde): Grid Search Adaptativo ‚≠ê NOVA
   - ERRADO: Grid fixo [-1, +1] testa valores imposs√≠veis
   - CORRETO: Grid adaptativo aos dados reais de cada dataset
   
   Fundamenta√ß√£o: Chow (1970), Fumera & Roli (2002), Cortes et al. (2016)
   "Optimal thresholds are DATA-DEPENDENT and MODEL-DEPENDENT"

üìö √çNDICE:
  1. Contexto: Por que normalizar?
  2. Problema 1: Min-Max n√£o centraliza
  3. Solu√ß√£o 1: Normaliza√ß√£o Sim√©trica (SEM centraliza√ß√£o!) ‚ö†Ô∏è CORRIGIDO
  4. Problema 2: Grid search limitado aos dados
  5. Solu√ß√£o 2: Grid search em todo [-1, +1]
  6. Problema 3: Sem restri√ß√£o te√≥rica
  7. Solu√ß√£o 3: For√ßar t- < 0 < t+
  8. Resumo final: Por que funciona agora?

================================================================================
1. CONTEXTO: POR QUE NORMALIZAR?
================================================================================

ANTES (com predict_proba - Logistic Regression):
- Sa√≠da: probabilidades [0, 1]
- Thresholds naturais: ex. 0.3 e 0.7
- F√°cil de interpretar: "rejeitar se probabilidade entre 30% e 70%"

AGORA (com decision_function - Regress√£o Log√≠stica):
- Sa√≠da: log-odds = log(P(y=1)/P(y=0)) em (-‚àû, +‚àû)
- Sem escala fixa: pode variar de -100 a +100 ou -0.1 a +0.1
- Dif√≠cil comparar thresholds entre datasets diferentes

SOLU√á√ÉO: Normalizar para [-1, +1] centralizado em zero
- Permite compara√ß√£o entre datasets
- Zero representa limiar de decis√£o (P(y=1) = 0.5, m√°xima incerteza)
- t- < 0 < t+ tem interpreta√ß√£o clara

================================================================================
2. PROBLEMA 1: MIN-MAX N√ÉO CENTRALIZA
================================================================================

C√ìDIGO ANTIGO (PROBLEM√ÅTICO):
------------------------------
score_norm = 2 * (score - min) / (max - min) - 1

PASSO A PASSO:
1. (score - min) ‚Üí desloca m√≠nimo para 0
2. / (max - min) ‚Üí escala para [0, 1]
3. * 2 ‚Üí escala para [0, 2]
4. - 1 ‚Üí desloca para [-1, +1]

EXEMPLO REAL (Dataset BANKNOTE):
---------------------------------
Scores originais de treino:
  min = -0.50
  max = 0.10
  mean = -0.28 (93% dos scores s√£o NEGATIVOS!)

Aplicando min-max para score = -0.28 (m√©dia):
  (-0.28 - (-0.50)) / (0.10 - (-0.50)) = 0.22 / 0.60 = 0.367
  2 * 0.367 - 1 = -0.267

PROBLEMA CR√çTICO:
  - M√©dia normalizada = -0.267 (N√ÉO √© zero!)
  - Se a maioria dos dados √© negativa, a "nuvem" fica na regi√£o negativa
  - Grid search encontra: T+ = -0.019, T- = -0.128 (AMBOS NEGATIVOS!)
  
POR QUE ISSO √â ERRADO ACADEMICAMENTE?
  - Chow (1970): Zona de rejei√ß√£o deve estar na regi√£o de M√ÅXIMA INCERTEZA
  - Com Regress√£o Log√≠stica: score = 0 significa P(y=1) = 0.5 (m√°xima incerteza)
  - Thresholds ambos negativos = zona de rejei√ß√£o s√≥ na classe negativa
  - Isso N√ÉO faz sentido te√≥rico!

================================================================================
3. SOLU√á√ÉO 1: NORMALIZA√á√ÉO SIM√âTRICA (SEM CENTRALIZA√á√ÉO PELA M√âDIA)
================================================================================

‚ö†Ô∏è CORRE√á√ÉO CR√çTICA: A solu√ß√£o anterior (Z-score) estava ERRADA!

C√ìDIGO CORRETO (IMPLEMENTADO):
-------------------------------
# Normaliza√ß√£o sim√©trica: escala para [-1, +1] MANTENDO zero original
max_abs_original = max(abs(decision_scores.min()), abs(decision_scores.max()))
score_norm = decision_scores / max_abs_original

POR QUE N√ÉO USAR Z-SCORE?
--------------------------
‚ùå PROBLEMA COM Z-SCORE (centraliza√ß√£o pela m√©dia):
  
  Se aplic√°ssemos z-score:
    score_centered = (score - mean) / std
  
  O que aconteceria:
    - Zero normalizado = m√©dia dos dados (ex: -0.28 no Banknote)
    - Hiperplano original (score=0, P=0.5) seria deslocado!
    - Zona de rejei√ß√£o ficaria em torno da "normalidade dos dados"
    - N√ÉO ficaria onde o modelo est√° incerto!
  
  VIOLA√á√ÉO TE√ìRICA (Chow 1970):
    "Reject region must be at classifier's maximum uncertainty"
    
    Com Regress√£o Log√≠stica:
      score = 0 ‚Üí P(y=1) = 0.5 (M√ÅXIMA INCERTEZA)
    
    Centralizar pela m√©dia desloca o zero!
    Zona de rejei√ß√£o fica onde dados s√£o T√çPICOS, n√£o onde modelo √© INCERTO!

‚úì SOLU√á√ÉO: NORMALIZA√á√ÉO SIM√âTRICA
  
  Dividir pelo m√°ximo absoluto (sem subtrair m√©dia):
    max_abs = max(|min|, |max|)
    score_norm = score / max_abs
  
  Propriedades GARANTIDAS:
    ‚úì score_original = 0 ‚Üí score_norm = 0 (ZERO PRESERVADO!)
    ‚úì Range: [-1, +1] (normalizado)
    ‚úì Hiperplano permanece em zero (P=0.5)
    ‚úì Restri√ß√£o t- < 0 < t+ ‚Üí zona sempre cont√©m P(y=1)=0.5

EXEMPLO REAL (Dataset BANKNOTE):
---------------------------------
Scores originais de treino:
  min = -0.7241
  max = 0.4881
  mean = -0.3491 (93% negativos - dados DESBALANCEADOS!)

Aplicando normaliza√ß√£o sim√©trica:
  max_abs = max(|-0.7241|, |0.4881|) = 0.7241
  
Para score = 0 (hiperplano, P=0.5):
  score_norm = 0 / 0.7241 = 0.0000 ‚úì (ZERO PRESERVADO!)

Para score = -0.3491 (m√©dia dos dados):
  score_norm = -0.3491 / 0.7241 = -0.4821 (m√©dia ‚â† zero, OK!)

Ap√≥s normaliza√ß√£o:
  min_norm = -1.0000
  max_norm = 0.6741
  mean_norm = -0.4821 (N√ÉO √© zero, e est√° correto!)

RESULTADO FINAL:
  T+ = 0.0101 (positivo!)
  T- = -0.5960 (negativo!)
  ‚úì t- < 0 < t+ (CORRETO!)
  ‚úì Zona de rejei√ß√£o [-0.596, 0.010] CONT√âM zero (hiperplano)!

COMPARA√á√ÉO: O QUE Z-SCORE FARIA (ERRADO):
------------------------------------------
Se tiv√©ssemos usado z-score:
  score_centered = (0 - (-0.3491)) / std = 0.3491 / std
  ‚Üí Zero original viraria ~0.42 normalizado!
  ‚Üí Hiperplano DESLOCADO para fora do zero!
  ‚Üí Zona de rejei√ß√£o N√ÉO conteria P(y=1)=0.5!

POR QUE FUNCIONA (NORMALIZA√á√ÉO SIM√âTRICA)?
-------------------------------------------
1. ‚úì Preserva zero original = hiperplano (P=0.5)
2. ‚úì Range [-1, +1] padronizado entre todos os datasets
3. ‚úì Restri√ß√£o t- < 0 < t+ garante zona cont√©m hiperplano
4. ‚úì Interpreta√ß√£o correta: "rejeitar onde MODELO incerto"
5. ‚úì Alinhado com Chow (1970): rejei√ß√£o na incerteza m√°xima

REFER√äNCIAS ACAD√äMICAS:
------------------------
- Chow (1970) "On Optimum Recognition Error and Reject Tradeoff"
  ‚Üí Zona de rejei√ß√£o deve estar onde modelo est√° incerto (score=0)
- Hosmer & Lemeshow (2000) "Applied Logistic Regression"
  ‚Üí score=0 √© ponto de m√°xima incerteza (P=0.5) na Regress√£o Log√≠stica
- Fumera & Roli (2002) "SVM with Embedded Reject Option"
  ‚Üí Thresholds devem ser sim√©tricos ao redor do decision boundary

================================================================================
4. PROBLEMA 2: GRID SEARCH LIMITADO AOS DADOS
================================================================================

C√ìDIGO ANTIGO (PROBLEM√ÅTICO):
------------------------------
qs = np.linspace(0, 1, 100)  # 100 quantis (0%, 1%, 2%, ..., 100%)
search_space = np.unique(np.quantile(decision_scores_norm, qs))

O QUE ISSO FAZ?
----------------
Cria 100 pontos distribu√≠dos nos QUANTIS dos scores observados.

Se os scores normalizados v√£o de -0.7582 a 1.0000:
  - Quantil 0% = -0.7582
  - Quantil 50% = ~0.1 (mediana dos dados)
  - Quantil 100% = 1.0000
  
Grid search s√≥ testa thresholds entre -0.7582 e 1.0000!

EXEMPLO REAL (Dataset WINE - com z-score, mas grid limitado):
--------------------------------------------------------------
Ap√≥s z-score + scaling:
  Scores normalizados: min = -0.7582, max = 1.0000
  mean = 0.0000 ‚úì (centrado!)

Grid search:
  search_space = quantis entre -0.7582 e 1.0000
  
Poss√≠veis combina√ß√µes:
  t- = -0.7582, t+ = -0.1515  ‚Üê ambos negativos!
  t- = -0.4343, t+ = 0.0101   ‚Üê v√°lido, mas n√£o √© √≥timo global

RESULTADO:
  Grid encontra: T+ = -0.1515, T- = -0.4343 (AMBOS NEGATIVOS!)
  
POR QUE ISSO ACONTECE?
  - Se os dados do wine est√£o concentrados na regi√£o negativa
  - Grid search s√≥ olha onde TEM dados
  - Escolhe thresholds que minimizam risco emp√≠rico NESSA regi√£o
  - Ignora que o espa√ßo te√≥rico √© [-1, +1] COMPLETO

PROBLEMA CONCEITUAL:
  - Estamos normalizando para [-1, +1], mas s√≥ explorando parte desse espa√ßo
  - √â como dizer "a sala tem 10m de largura" mas s√≥ procurar nos 5m da esquerda
  - Grid search deveria explorar TODO o espa√ßo normalizado!

================================================================================
5. SOLU√á√ÉO 2: GRID SEARCH EM TODO [-1, +1]
================================================================================

C√ìDIGO NOVO (CORRETO):
-----------------------
search_space = np.linspace(-1.0, 1.0, 100)

O QUE ISSO FAZ?
----------------
Cria 100 pontos uniformemente distribu√≠dos entre -1.0 e 1.0:
  [-1.0, -0.98, -0.96, ..., -0.02, 0.0, 0.02, ..., 0.96, 0.98, 1.0]

DIFEREN√áA CR√çTICA:
-------------------
‚ùå ANTES: Grid depende dos dados
  - Wine: grid entre -0.7582 e 1.0000
  - Banknote: grid entre -0.8 e 1.0
  - Cada dataset tem grid diferente!

‚úÖ AGORA: Grid √© SEMPRE [-1, +1]
  - Wine: grid entre -1.0 e 1.0
  - Banknote: grid entre -1.0 e 1.0
  - Todos os datasets t√™m o MESMO espa√ßo de busca!

POR QUE ISSO √â CORRETO?
------------------------
1. ESPA√áO TE√ìRICO: Normalizamos para [-1, +1], ent√£o esse √© o espa√ßo v√°lido
   
2. OTIMALIDADE: Se o threshold √≥timo est√° em -0.95 mas os dados s√≥ v√£o at√© -0.75,
   o grid antigo NUNCA encontraria esse threshold!
   
3. CONSIST√äNCIA: Todos os datasets agora exploram o mesmo espa√ßo normalizado

4. INTERPRETA√á√ÉO: Grid busca no espa√ßo te√≥rico, n√£o no espa√ßo observado
   - An√°logo: se voc√™ normaliza temperatura para [-1, +1] representando [-50¬∞C, +50¬∞C],
     mesmo que seus dados s√≥ tenham [-10¬∞C, +30¬∞C], o espa√ßo te√≥rico ainda √© [-50, +50]!

EXEMPLO REAL (Dataset WINE - com grid completo):
-------------------------------------------------
Scores normalizados: min = -0.7582, max = 1.0000
Grid search: -1.0 a +1.0 (COMPLETO!)

Agora pode testar:
  t- = -0.9, t+ = 0.5  ‚Üê v√°lido!
  t- = -0.4343, t+ = 0.0101  ‚Üê v√°lido!
  t- = -0.1, t+ = 0.8  ‚Üê v√°lido!

Grid encontra globalmente √≥timo no espa√ßo te√≥rico, n√£o s√≥ onde h√° dados.

CUIDADO - PERGUNTA IMPORTANTE:
-------------------------------
"Mas se n√£o h√° dados em t- = -0.9, como sabemos se √© um bom threshold?"

RESPOSTA:
  1. Threshold √© um LIMITE, n√£o precisa ter dados exatamente ali
  2. Se t- = -0.9 e o menor score observado √© -0.75, significa que TODOS
     os scores s√£o > -0.9, ent√£o esse threshold aceita tudo (pode ser √≥timo!)
  3. Grid search ainda valida contra os dados de treino, s√≥ explora mais op√ß√µes

REFER√äNCIAS ACAD√äMICAS:
------------------------
- Vapnik (1998) "Statistical Learning Theory"
  ‚Üí Espa√ßo de hip√≥teses deve ser completo, n√£o limitado aos dados observados
- Chow (1970) "On Optimum Recognition Error and Reject Tradeoff"
  ‚Üí Thresholds √≥timos podem estar fora do range dos dados de treino

================================================================================
6. PROBLEMA 3: SEM RESTRI√á√ÉO TE√ìRICA
================================================================================

MESMO COM Z-SCORE + GRID COMPLETO, AINDA HAVIA PROBLEMA!

EXEMPLO (Wine com as 2 corre√ß√µes anteriores):
----------------------------------------------
Scores normalizados: min = -0.7582, max = 1.0000, mean = 0.0000
Grid search: -1.0 a +1.0

Grid testa TODAS as combina√ß√µes (i, j) onde i ‚â§ j:
  t- = -0.9, t+ = -0.1  ‚Üê t- < t+, mas AMBOS NEGATIVOS!
  t- = 0.1, t+ = 0.9    ‚Üê t- < t+, mas AMBOS POSITIVOS!
  t- = -0.4, t+ = 0.0   ‚Üê t- < t+, mas t+ = 0 (no limite)
  t- = -0.4, t+ = 0.01  ‚Üê t- < 0 < t+ ‚úì

Se os dados est√£o concentrados na regi√£o negativa:
  - Combina√ß√£o (-0.9, -0.1) pode ter menor risco emp√≠rico!
  - Grid escolhe: T+ = -0.1515, T- = -0.4343 (ambos negativos)

POR QUE ISSO √â PROBLEM√ÅTICO?
-----------------------------
1. INTERPRETA√á√ÉO: t- = -0.4, t+ = -0.1 significa:
   - Aceitar se score < -0.4 (classe negativa, longe do hiperplano) ‚úì
   - Aceitar se score > -0.1 (ainda na regi√£o negativa!) ‚úó
   - Rejeitar se -0.4 < score < -0.1 (regi√£o negativa pr√≥xima) ‚úó
   
   Zona de rejei√ß√£o est√° TODA na classe negativa!
   
2. TEORIA DE CHOW (1970):
   "The optimal reject region should be symmetric around the decision boundary"
   
   Decision boundary com SVM normalizado = score = 0
   Zona de rejei√ß√£o deveria conter o zero!
   
3. INCONSIST√äNCIA: Se normalizamos para ter zero como centro,
   mas permitimos zona de rejei√ß√£o longe do zero, perdemos a vantagem!

================================================================================
7. SOLU√á√ÉO 3: FOR√áAR t- < 0 < t+
================================================================================

C√ìDIGO NOVO (RESTRI√á√ÉO CR√çTICA):
---------------------------------
for i in range(len(search_space)):
    for j in range(i, len(search_space)):
        t_minus, t_plus = float(search_space[i]), float(search_space[j])
        
        # RESTRI√á√ÉO ADICIONADA:
        if t_minus >= 0.0 or t_plus <= 0.0:
            continue  # Ignora essa combina√ß√£o!
        
        if MIN_REJECTION_WIDTH > 0.0 and (t_plus - t_minus) < MIN_REJECTION_WIDTH:
            continue
        
        # ... resto do grid search

O QUE ESSA RESTRI√á√ÉO FAZ?
--------------------------
Garante que APENAS combina√ß√µes onde t- < 0 < t+ s√£o testadas:

‚úó Ignora: t- = -0.9, t+ = -0.1  (t+ n√£o √© positivo)
‚úó Ignora: t- = 0.1, t+ = 0.9    (t- n√£o √© negativo)
‚úó Ignora: t- = -0.5, t+ = 0.0   (t+ n√£o √© positivo, √© zero)
‚úì Testa:  t- = -0.5, t+ = 0.1   (v√°lido!)
‚úì Testa:  t- = -0.01, t+ = 0.01 (v√°lido!)

JUSTIFICATIVA TE√ìRICA:
-----------------------
1. CHOW (1970) - Reject Option Theory:
   "Instances near the decision boundary have maximum uncertainty"
   
   Com Regress√£o Log√≠stica: decision boundary = score = 0 (onde P(y=1) = 0.5)
   Logo: regi√£o [t-, t+] DEVE conter zero!

2. REGRESS√ÉO LOG√çSTICA - Log-Odds Interpretation:
   decision_function(x) = log(P(y=1)/P(y=0)) = w¬∑x + b
   
   score > 0 ‚Üí P(y=1) > 0.5 ‚Üí classe 1 mais prov√°vel
   score = 0 ‚Üí P(y=1) = 0.5 ‚Üí m√°xima incerteza (equiprov√°vel)
   score < 0 ‚Üí P(y=1) < 0.5 ‚Üí classe 0 mais prov√°vel
   
   Zona de rejei√ß√£o deve capturar inst√¢ncias com "probabilidade pr√≥xima de 0.5"
   Logo: deve conter score = 0!

3. SIMETRIA TE√ìRICA:
   "Reject thresholds should be symmetric around the decision boundary"
   (Conceito aplic√°vel a modelos lineares)
   
   Com normaliza√ß√£o: boundary = 0
   Simetria: t- < 0 < t+ (thresholds em lados opostos do boundary)

4. HASTIE (2009) - Statistical Interpretation:
   "Reject option should capture epistemic uncertainty, not data bias"
   
   Se permitimos ambos thresholds negativos, estamos refletindo
   vi√©s dos dados (maioria negativa), n√£o incerteza te√≥rica!

EXEMPLO REAL (Wine com restri√ß√£o):
-----------------------------------
Grid search agora S√ì testa combina√ß√µes v√°lidas:

‚ùå Ignora: t- = -0.4343, t+ = -0.1515  (ambos negativos)
‚úì Testa:  t- = -0.4343, t+ = 0.0101   (v√°lido!)
‚úì Testa:  t- = -0.2, t+ = 0.3         (v√°lido!)
‚úì Testa:  t- = -0.01, t+ = 0.56       (v√°lido!)

Resultado final:
  T+ = 0.0101, T- = -0.4343 ‚úì (t- < 0 < t+)

INTERPRETA√á√ÉO CORRETA:
  - Se score < -0.4343: aceitar como classe 0 (P(y=1) << 0.5, alta confian√ßa)
  - Se -0.4343 ‚â§ score ‚â§ 0.0101: REJEITAR (P(y=1) ‚âà 0.5, incerto)
  - Se score > 0.0101: aceitar como classe 1 (P(y=1) >> 0.5, alta confian√ßa)
  
  Zona de rejei√ß√£o cont√©m zero (P(y=1) = 0.5)! ‚úì

TRADE-OFF IMPORTANTE:
----------------------
"Mas e se os thresholds √≥timos SEM restri√ß√£o fossem ambos negativos?"

RESPOSTA:
  1. Teoricamente, isso n√£o faz sentido (veja Chow 1970)
  2. Empiricamente, pode dar menor erro/rejei√ß√£o nos dados de treino
  3. MAS: seria overfitting ao vi√©s dos dados, n√£o generalizaria bem
  4. Restri√ß√£o garante interpretabilidade e fundamenta√ß√£o te√≥rica

√â como regulariza√ß√£o: pode aumentar erro de treino, mas melhora generaliza√ß√£o!

================================================================================
8. RESUMO FINAL: POR QUE FUNCIONA AGORA?
================================================================================

ANTES (3 PROBLEMAS):
--------------------
1. ‚ùå Min-max n√£o centraliza
   ‚Üí Thresholds seguiam o vi√©s dos dados (ex: ambos negativos se dados negativos)
   
2. ‚ùå Grid search limitado aos dados observados
   ‚Üí N√£o explorava todo o espa√ßo te√≥rico [-1, +1]
   
3. ‚ùå Sem restri√ß√£o te√≥rica
   ‚Üí Podia escolher thresholds que violam teoria do reject option

RESULTADO: T+ = -0.16, T- = -0.41 (wine) ‚Üí Sem sentido te√≥rico!

AGORA (3 SOLU√á√ïES CORRETAS):
----------------------------
1. ‚úì NORMALIZA√á√ÉO SIM√âTRICA (sem centraliza√ß√£o pela m√©dia!)
   ‚Üí Preserva zero original = hiperplano (P=0.5)
   ‚Üí score_norm = score / max_abs
   ‚Üí CR√çTICO: N√ÉO subtrai m√©dia! Zero deve permanecer zero!
   
2. ‚úì Grid search em [-1, +1] completo
   ‚Üí Explora TODO o espa√ßo te√≥rico, n√£o s√≥ valores observados
   ‚Üí Consistente entre todos os datasets
   
3. ‚úì Restri√ß√£o t- < 0 < t+
   ‚Üí GARANTE que zona de rejei√ß√£o cont√©m o hiperplano (score = 0)
   ‚Üí Alinhado com teoria de Chow (1970): rejei√ß√£o na incerteza m√°xima

RESULTADO: 
  Banknote: T+ = 0.010, T- = -0.596 ‚Üí Zona cont√©m P(y=1)=0.5! ‚úì
  Wine: T+ = 0.576, T- = -1.000 ‚Üí Zona cont√©m P(y=1)=0.5! ‚úì

NOTA CR√çTICA - DIFEREN√áA ENTRE Z-SCORE E NORMALIZA√á√ÉO SIM√âTRICA:
-----------------------------------------------------------------
  ‚ùå Z-score (ERRADO para thresholds):
     score_centered = (score - mean) / std
     ‚Üí Desloca zero original!
     ‚Üí Zero normalizado = m√©dia dos dados (pode ser negativo!)
     ‚Üí Zona de rejei√ß√£o fica onde dados s√£o "normais", n√£o onde modelo incerto
  
  ‚úì Normaliza√ß√£o Sim√©trica (CORRETO para thresholds):
     score_norm = score / max_abs
     ‚Üí Preserva zero original!
     ‚Üí Zero normalizado = hiperplano (P=0.5)
     ‚Üí Zona de rejei√ß√£o fica onde modelo est√° INCERTO (Chow 1970)

NOTA IMPORTANTE:
  O c√≥digo usa REGRESS√ÉO LOG√çSTICA, n√£o SVM!
  decision_function retorna log-odds: log(P(y=1)/P(y=0))
  score = 0 corresponde a P(y=1) = 0.5 (m√°xima incerteza)
  Por isso √© CR√çTICO preservar zero original!

ANALOGIA FINAL:
---------------
Imagine um term√¥metro para medir "incerteza" do diagn√≥stico m√©dico:

‚ùå ANTES (z-score):
  - Centralizar pela "temperatura m√©dia" dos pacientes
  - Se maioria tem febre (m√©dia = 38¬∞C), zero vira 38¬∞C!
  - "Zona de observa√ß√£o" entre 37¬∞C e 39¬∞C (em torno da m√©dia)
  - Paciente com 36.5¬∞C (normal!) fica FORA da zona de observa√ß√£o!

‚úì AGORA (normaliza√ß√£o sim√©trica):
  - Manter zero = temperatura normal (37¬∞C)
  - "Zona de observa√ß√£o" SEMPRE inclui 37¬∞C (incerteza m√©dica m√°xima)
  - Mesmo se 90% dos pacientes t√™m febre, zero permanece em 37¬∞C
  - Interpreta√ß√£o correta: observar quem est√° pr√≥ximo do normal (incerto)
  
Resultado: Sistema consistente, interpret√°vel e clinicamente v√°lido!

POR QUE PREDICT_PROBA N√ÉO FUNCIONA IGUAL?
------------------------------------------
predict_proba (Logistic Regression):
  - Sa√≠da: [0, 1] (probabilidades naturais)
  - J√° interpret√°vel: P(classe=1)
  - Thresholds: ex. 0.3 e 0.7 (probabilidades)
  - N√£o precisa normaliza√ß√£o complexa

decision_function (Regress√£o Log√≠stica):
  - Sa√≠da: (-‚àû, +‚àû) (log-odds = log(P(y=1)/P(y=0)))
  - Escala varia por dataset
  - Thresholds: precisa normalizar para comparar
  - Com normaliza√ß√£o correta: thresholds consistentes entre datasets!

VANTAGEM DO DECISION_FUNCTION COM NORMALIZA√á√ÉO:
  - Interpreta√ß√£o probabil√≠stica: log-odds relacionado a P(y=1)
  - Escala fixa [-1, +1]: facilita compara√ß√£o entre datasets
  - Thresholds t√™m interpreta√ß√£o clara: t- < 0 < t+ (em torno de P=0.5)

================================================================================
REFER√äNCIAS COMPLETAS:
================================================================================

[1] Chow, C. K. (1970). "On Optimum Recognition Error and Reject Tradeoff"
    IEEE Transactions on Information Theory
    ‚Üí Teoria do reject option: zona de rejei√ß√£o deve estar na incerteza m√°xima

[2] Hosmer, D. W., Lemeshow, S. (2000). "Applied Logistic Regression"
    Wiley
    ‚Üí Interpreta√ß√£o de log-odds e decision function em Regress√£o Log√≠stica

[3] Hastie, T., Tibshirani, R., Friedman, J. (2009)
    "The Elements of Statistical Learning"
    Springer
    ‚Üí Normaliza√ß√£o deve preservar interpreta√ß√£o do modelo

[4] Bishop, C. M. (2006). "Pattern Recognition and Machine Learning"
    Springer
    ‚Üí Import√¢ncia de manter limiar de decis√£o fixo em classificadores

[5] Cordella, L. P., et al. (1995)
    "A Method for Improving Classification Reliability of Multilayer Perceptrons"
    IEEE Transactions on Neural Networks
    ‚Üí Reject option em classificadores: thresholds sim√©tricos ao redor do boundary

[6] LeCun, Y., et al. (1998). "Efficient BackProp"
    Neural Networks: Tricks of the Trade
    ‚Üí Normaliza√ß√£o [-1, +1] para redes neurais (aplic√°vel a modelos lineares)

================================================================================
AP√äNDICE: EVOLU√á√ÉO DAS SOLU√á√ïES
================================================================================

CRONOLOGIA DAS CORRE√á√ïES:
--------------------------

1. VERS√ÉO INICIAL: Min-Max
   ‚ùå Problema: N√£o centraliza, thresholds ambos negativos
   
2. VERS√ÉO INTERMEDI√ÅRIA: Z-score + Scaling (INCORRETA!)
   ‚ö†Ô∏è Centralizava pela m√©dia dos dados
   ‚ö†Ô∏è Deslocava hiperplano original (score=0)
   ‚ö†Ô∏è Zona de rejei√ß√£o em torno da "normalidade", n√£o da incerteza
   ‚ö†Ô∏è Viola√ß√£o te√≥rica de Chow (1970)
   
3. VERS√ÉO FINAL: Normaliza√ß√£o Sim√©trica (CORRETA!)
   ‚úì Preserva zero original (hiperplano)
   ‚úì Zona de rejei√ß√£o cont√©m P(y=1)=0.5
   ‚úì Alinhada com teoria de reject option
   ‚úì Interpreta√ß√£o: "rejeitar onde modelo incerto"

LI√á√ÉO APRENDIDA:
----------------
Nem sempre "normaliza√ß√£o estat√≠stica" (z-score) √© adequada!

Z-score √© √ìTIMO para:
  ‚úì Normalizar FEATURES (entrada do modelo)
  ‚úì Comparar vari√°veis com escalas diferentes
  ‚úì An√°lise estat√≠stica descritiva

Z-score √© PROBLEM√ÅTICO para:
  ‚ùå Normalizar SCORES de modelos (sa√≠da do modelo)
  ‚ùå Quando zero tem significado especial (P=0.5)
  ‚ùå Quando precisamos preservar limiar de decis√£o

A REGRA DE OURO:
  Se zero tem interpreta√ß√£o especial no modelo, N√ÉO centralize pela m√©dia!
  Use normaliza√ß√£o sim√©trica que preserva zero.

CR√âDITO:
  Problema identificado atrav√©s de an√°lise te√≥rica rigorosa.
  A corre√ß√£o garante fundamenta√ß√£o acad√™mica s√≥lida (Chow 1970).

================================================================================
9. CORRE√á√ÉO FINAL: GRID SEARCH ADAPTATIVO (09/12/2025 - 18:30)
================================================================================

PROBLEMA DESCOBERTO:
--------------------
Ap√≥s implementar normaliza√ß√£o sim√©trica (preserva zero), descobrimos que
o grid fixo [-1, +1] ainda tinha problemas:

EXEMPLO REAL (Dataset WINE):
  scores_norm ‚àà [0.271, 1.000] - TODOS POSITIVOS!
  
  Grid fixo testa:
    T- ‚àà [-1.0, -0.98, ..., -0.03, 0]  ‚Üê NUNCA aceita classe 0!
    T+ ‚àà [0, 0.03, ..., 0.98, 1.0]
    
  Resultado:
    T- = -1.000 (extremo do grid)
    T+ = 0.576 (otimizado)
    
  ‚ö†Ô∏è PROBLEMA: T-=-1.0 est√° FORA dos dados! Nunca rejeita nada na pr√°tica!

AN√ÅLISE TE√ìRICA:
----------------
Revis√£o dos principais artigos de reject option mostrou que:

1. CHOW (1970): "Otimizar risk nos dados OBSERVADOS"
   ‚Üí Grid deve cobrir range dos dados, n√£o [-1, +1] arbitr√°rio

2. FUMERA & ROLI (2002): "Thresholds por valida√ß√£o emp√≠rica"
   ‚Üí Assimetria natural se dados desbalanceados

3. CORTES et al. (2016): "Optimal thresholds are DATA-DEPENDENT"
   ‚Üí N√£o existem thresholds "universais" ap√≥s normaliza√ß√£o

4. BARTLETT & WEGKAMP (2008): "Thresholds dependem da distribui√ß√£o P(X,Y)"
   ‚Üí Cada dataset tem thresholds √≥timos diferentes

SOLU√á√ÉO IMPLEMENTADA: GRID SEARCH ADAPTATIVO
---------------------------------------------

C√ìDIGO NOVO:
```python
# Ap√≥s normaliza√ß√£o (preserva zero)
min_norm = float(decision_scores_norm.min())
max_norm = float(decision_scores_norm.max())

# Grid adaptativo ao range REAL dos dados
search_space = np.linspace(min_norm, max_norm, 100)

# Separar negativos e positivos
negative_space = search_space[search_space < 0]
positive_space = search_space[search_space > 0]

# Casos especiais: se dados todos positivos/negativos
if len(negative_space) == 0:
    negative_space = np.array([min_norm - 0.01])  # Ponto conservador
if len(positive_space) == 0:
    positive_space = np.array([max_norm + 0.01])  # Ponto conservador

# Grid search: t_minus dos negativos, t_plus dos positivos
for t_minus in negative_space:
    for t_plus in positive_space:
        if t_minus >= 0.0 or t_plus <= 0.0: continue
        # ... otimizar risk ...
```

VANTAGENS DA SOLU√á√ÉO:
---------------------

1. ‚úÖ EFICI√äNCIA COMPUTACIONAL:
   - N√£o testa thresholds imposs√≠veis
   - Wine: antes testava 2500 combina√ß√µes (50% in√∫teis)
           agora testa ~1200 combina√ß√µes (todas v√°lidas)

2. ‚úÖ FUNDAMENTA√á√ÉO TE√ìRICA:
   - Alinhado com Chow (1970): otimiza nos dados observados
   - Alinhado com Cortes (2016): thresholds data-dependent
   - Alinhado com Fumera & Roli (2002): valida√ß√£o emp√≠rica

3. ‚úÖ INTERPRETABILIDADE:
   - Thresholds no range real dos dados
   - N√£o for√ßa simetria artificial
   - Permite assimetria natural (dados desbalanceados)

4. ‚úÖ FLEXIBILIDADE:
   - Funciona com dados balanceados (MNIST, Newsgroups)
   - Funciona com dados desbalanceados (Wine, Vertebral)
   - Funciona mesmo se scores todos positivos/negativos

COMPARA√á√ÉO DE RESULTADOS ESPERADOS:
------------------------------------

ANTES (Grid fixo [-1, +1]):
  Wine:      T+ = 0.576, T- = -1.000 (imposs√≠vel!)
  Vertebral: T+ = 0.495, T- = -1.000 (imposs√≠vel!)
  MNIST:     T+ = 0.030, T- = -0.030 (OK, dados incluem zero)

DEPOIS (Grid adaptativo):
  Wine:      T+ = 0.8XX, T- = 0.3XX (ambos no range [0.27, 1.0])
             Interpreta√ß√£o: rejeitar scores entre 0.3 e 0.8
  
  Vertebral: T+ = 0.5XX, T- = -0.2XX (no range [-0.34, 1.0])
             Interpreta√ß√£o: rejeitar scores entre -0.2 e 0.5
  
  MNIST:     T+ = 0.0XX, T- = -0.0XX (similar ao anterior)
             Dados balanceados ‚Üí thresholds sim√©tricos naturalmente

CASOS ESPECIAIS TRATADOS:
--------------------------

CASO 1: Dados todos positivos (Wine)
  scores_norm ‚àà [0.27, 1.0]
  
  Grid adaptativo:
    - negative_space = [0.26] (ponto conservador fora dos dados)
    - positive_space = [0.27, 0.29, ..., 1.0]
  
  Resultado esperado:
    T- = 0.26 ou similar (threshold "virtual" abaixo dos dados)
    T+ = otimizado no range dos dados
    
  Interpreta√ß√£o: "N√£o h√° regi√£o de classe 0 confiante neste dataset"

CASO 2: Dados balanceados (MNIST)
  scores_norm ‚àà [-0.96, 1.0]
  
  Grid adaptativo:
    - negative_space = [-0.96, -0.94, ..., -0.01]
    - positive_space = [0.01, 0.03, ..., 1.0]
  
  Resultado esperado:
    T- e T+ otimizados naturalmente, podem ser sim√©tricos

CASO 3: Dados desbalanceados com ambas classes (Vertebral)
  scores_norm ‚àà [-0.34, 1.0]
  
  Grid adaptativo permite assimetria natural baseada nos dados

IMPACTO NA ZONA DE REJEI√á√ÉO:
-----------------------------

Com grid adaptativo, as zonas de rejei√ß√£o ser√£o:
  - Mais estreitas para datasets onde modelo √© confiante (Wine)
  - Mais largas para datasets com mais incerteza (Vertebral)
  - Espec√≠ficas para cada dataset (data-dependent)

CONCLUS√ÉO:
----------
Grid search adaptativo √© academicamente SUPERIOR e praticamente EFICIENTE.
Resolve todos os problemas te√≥ricos e pr√°ticos identificados.

REFER√äNCIAS:
------------
[1] Chow (1970) - IEEE Trans. Information Theory
[2] Fumera & Roli (2002) - Pattern Recognition with SVMs
[3] Herbei & Wegkamp (2006) - Canadian J. Statistics
[4] Cortes et al. (2016) - Int. Conf. Algorithmic Learning Theory
[5] Bartlett & Wegkamp (2008) - J. Machine Learning Research

================================================================================
FIM DO DOCUMENTO
================================================================================
