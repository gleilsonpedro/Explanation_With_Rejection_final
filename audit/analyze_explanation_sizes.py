"""
An√°lise das distribui√ß√µes de tamanho de explica√ß√µes por dataset e tipo de predi√ß√£o.
Compara PEAB e PuLP para entender anomalias.
"""
import json
from pathlib import Path
from typing import Dict, List
from collections import Counter

def load_json(path: Path) -> dict:
    with open(path, 'r', encoding='utf-8') as f:
        return json.load(f)

def analyze_dataset(dataset_name: str):
    """Analisa as distribui√ß√µes de tamanhos de explica√ß√µes para um dataset."""
    
    peab_path = Path(f'json/peab/{dataset_name}.json')
    pulp_path = Path(f'json/pulp/{dataset_name}.json')
    
    if not peab_path.exists() or not pulp_path.exists():
        print(f"‚ùå Arquivos n√£o encontrados para {dataset_name}")
        return
    
    peab_data = load_json(peab_path)
    pulp_data = load_json(pulp_path)
    
    print(f"\n{'='*80}")
    print(f"üìä AN√ÅLISE: {dataset_name.upper()}")
    print(f"{'='*80}")
    
    # Estat√≠sticas agregadas
    print("\nüìà ESTAT√çSTICAS AGREGADAS (PEAB):")
    for tipo in ['positive', 'negative', 'rejected']:
        stats = peab_data['explanation_stats'].get(tipo, {})
        if stats.get('count', 0) > 0:
            print(f"  {tipo.upper():10s}: "
                  f"Qtd={stats['count']:3d} | "
                  f"M√©dia={stats['mean_length']:.2f} | "
                  f"Min={stats['min_length']:2d} | "
                  f"Max={stats['max_length']:2d}")
    
    print("\nüìà ESTAT√çSTICAS AGREGADAS (PuLP):")
    for tipo_key, tipo_label in [('positiva', 'POSITIVE'), ('negativa', 'NEGATIVE'), ('rejeitada', 'REJECTED')]:
        stats = pulp_data['estatisticas_por_tipo'].get(tipo_key, {})
        if stats.get('instancias', 0) > 0:
            # Calcular min/max do PuLP manualmente
            tamanhos = []
            for expl in pulp_data['explicacoes']:
                if expl['tipo_predicao'] == tipo_key.upper():
                    tamanhos.append(expl['tamanho'])
            
            if tamanhos:
                print(f"  {tipo_label:10s}: "
                      f"Qtd={stats['instancias']:3d} | "
                      f"M√©dia={stats['tamanho_medio']:.2f} | "
                      f"Min={min(tamanhos):2d} | "
                      f"Max={max(tamanhos):2d}")
    
    # An√°lise detalhada das negativas no PuLP (problema principal)
    print("\nüîç DISTRIBUI√á√ÉO DETALHADA DAS NEGATIVAS (PuLP):")
    negativas_pulp = [e for e in pulp_data['explicacoes'] if e['tipo_predicao'] == 'NEGATIVA']
    
    if negativas_pulp:
        tamanhos_counter = Counter([e['tamanho'] for e in negativas_pulp])
        total_neg = len(negativas_pulp)
        
        print(f"  Total de negativas: {total_neg}")
        for tam in sorted(tamanhos_counter.keys()):
            count = tamanhos_counter[tam]
            pct = (count / total_neg) * 100
            bar = '‚ñà' * int(pct / 2)
            print(f"    {tam} features: {count:3d} inst√¢ncias ({pct:5.1f}%) {bar}")
        
        # Verificar se h√° muitas negativas com 5 ou 6 features
        grandes = sum(1 for e in negativas_pulp if e['tamanho'] >= 5)
        pct_grandes = (grandes / total_neg) * 100
        print(f"\n  ‚ö†Ô∏è  Negativas com ‚â•5 features: {grandes}/{total_neg} ({pct_grandes:.1f}%)")
    
    # An√°lise das rejeitadas
    print("\nüîç DISTRIBUI√á√ÉO DETALHADA DAS REJEITADAS (PuLP):")
    rejeitadas_pulp = [e for e in pulp_data['explicacoes'] if e['tipo_predicao'] == 'REJEITADA']
    
    if rejeitadas_pulp:
        tamanhos_counter = Counter([e['tamanho'] for e in rejeitadas_pulp])
        total_rej = len(rejeitadas_pulp)
        
        print(f"  Total de rejeitadas: {total_rej}")
        for tam in sorted(tamanhos_counter.keys()):
            count = tamanhos_counter[tam]
            pct = (count / total_rej) * 100
            bar = '‚ñà' * int(pct / 2)
            print(f"    {tam} features: {count:3d} inst√¢ncias ({pct:5.1f}%) {bar}")
    
    # Compara√ß√£o direta Negativas vs Rejeitadas
    if negativas_pulp and rejeitadas_pulp:
        media_neg = sum(e['tamanho'] for e in negativas_pulp) / len(negativas_pulp)
        media_rej = sum(e['tamanho'] for e in rejeitadas_pulp) / len(rejeitadas_pulp)
        
        print(f"\nüìä COMPARA√á√ÉO NEGATIVAS vs REJEITADAS:")
        print(f"  M√©dia Negativas: {media_neg:.2f} features")
        print(f"  M√©dia Rejeitadas: {media_rej:.2f} features")
        print(f"  Diferen√ßa: {media_rej - media_neg:+.2f} features")
        
        if media_neg > media_rej * 0.9:
            print(f"  ‚ö†Ô∏è  ANOMALIA: Negativas s√£o quase do mesmo tamanho que rejeitadas!")
        elif media_neg < media_rej * 0.7:
            print(f"  ‚úÖ NORMAL: Negativas s√£o menores que rejeitadas (como esperado)")
        else:
            print(f"  ‚ö†Ô∏è  BORDERLINE: Negativas est√£o pr√≥ximas das rejeitadas")

if __name__ == "__main__":
    # Datasets para an√°lise
    datasets = [
        'pima_indians_diabetes',
        'vertebral_column',
        'breast_cancer',
        'wine',
        'sonar'
    ]
    
    for dataset in datasets:
        try:
            analyze_dataset(dataset)
        except Exception as e:
            print(f"\n‚ùå Erro ao analisar {dataset}: {e}")
    
    print(f"\n{'='*80}")
    print("‚úÖ An√°lise conclu√≠da!")
    print(f"{'='*80}\n")
