===================================================================================
        RELATÓRIO DE OTIMIZAÇÃO DE HIPERPARÂMETROS (Logistic Regression)
===================================================================================
Critérios de seleção (prioridade):
  1. Maior Acurácia (accuracy)
  2. Maior F1-Score (em caso de empate na acurácia)
  3. Menor Número Médio de Coeficientes Não-Nulos (em caso de empate em ambos)


==================================================================================
 DATASET: SONAR
==================================================================================
Penalty  | Solver     | C       | Max_Iter | Acurácia     | F1-Score     | Avg Non-Zero Coeffs
----------------------------------------------------------------------------------
l2       | saga       | 0.01    | 200      | 0.8024*           | 0.8102             | 60.00
l2       | saga       | 0.01    | 500      | 0.8024            | 0.8102             | 60.00
l2       | saga       | 0.01    | 1000     | 0.8024            | 0.8102             | 60.00
l2       | saga       | 0.1     | 200      | 0.7979            | 0.8022             | 60.00
l2       | saga       | 0.1     | 500      | 0.7979            | 0.8022             | 60.00
l2       | saga       | 0.1     | 1000     | 0.7979            | 0.8022             | 60.00
l2       | liblinear  | 0.1     | 200      | 0.7979            | 0.7998             | 60.00
l2       | liblinear  | 0.1     | 500      | 0.7979            | 0.7998             | 60.00
l2       | liblinear  | 0.1     | 1000     | 0.7979            | 0.7998             | 60.00
l2       | saga       | 1       | 200      | 0.7886            | 0.8022             | 60.00

  -> MELHOR ESCOLHA PARA 'SONAR': {'penalty': 'l2', 'C': 0.01, 'max_iter': 200, 'solver': 'saga'} (*)

==================================================================================
 DATASET: PIMA_INDIANS_DIABETES
==================================================================================
Penalty  | Solver     | C       | Max_Iter | Acurácia     | F1-Score     | Avg Non-Zero Coeffs
----------------------------------------------------------------------------------
l2       | saga       | 10      | 200      | 0.7773*           | 0.6442             | 8.00
l2       | saga       | 10      | 500      | 0.7773            | 0.6442             | 8.00
l2       | saga       | 10      | 1000     | 0.7773            | 0.6442             | 8.00
l2       | saga       | 100     | 200      | 0.7773            | 0.6442             | 8.00
l2       | saga       | 100     | 500      | 0.7773            | 0.6442             | 8.00
l2       | saga       | 100     | 1000     | 0.7773            | 0.6442             | 8.00
l2       | saga       | 1       | 200      | 0.7760            | 0.6417             | 8.00
l2       | saga       | 1       | 500      | 0.7760            | 0.6417             | 8.00
l2       | saga       | 1       | 1000     | 0.7760            | 0.6417             | 8.00
l1       | liblinear  | 1       | 200      | 0.7760            | 0.6430             | 7.60

  -> MELHOR ESCOLHA PARA 'PIMA_INDIANS_DIABETES': {'penalty': 'l2', 'C': 10, 'max_iter': 200, 'solver': 'saga'} (*)

==================================================================================
 DATASET: BREAST_CANCER
==================================================================================
Penalty  | Solver     | C       | Max_Iter | Acurácia     | F1-Score     | Avg Non-Zero Coeffs
----------------------------------------------------------------------------------
l2       | liblinear  | 0.1     | 200      | 0.9807*           | 0.9849             | 30.00
l2       | liblinear  | 0.1     | 500      | 0.9807            | 0.9849             | 30.00
l2       | liblinear  | 0.1     | 1000     | 0.9807            | 0.9849             | 30.00
l1       | saga       | 1       | 200      | 0.9789            | 0.9836             | 24.30
l2       | liblinear  | 1       | 200      | 0.9789            | 0.9834             | 30.00
l2       | liblinear  | 1       | 500      | 0.9789            | 0.9834             | 30.00
l2       | liblinear  | 1       | 1000     | 0.9789            | 0.9834             | 30.00
l2       | saga       | 0.1     | 200      | 0.9772            | 0.9823             | 30.00
l2       | saga       | 0.1     | 500      | 0.9772            | 0.9823             | 30.00
l2       | saga       | 0.1     | 1000     | 0.9772            | 0.9823             | 30.00

  -> MELHOR ESCOLHA PARA 'BREAST_CANCER': {'penalty': 'l2', 'C': 0.1, 'max_iter': 200, 'solver': 'liblinear'} (*)

==================================================================================
 DATASET: VERTEBRAL_COLUMN
==================================================================================
Penalty  | Solver     | C       | Max_Iter | Acurácia     | F1-Score     | Avg Non-Zero Coeffs
----------------------------------------------------------------------------------
l2       | saga       | 1       | 200      | 0.8516*           | 0.8897             | 6.00
l2       | saga       | 1       | 500      | 0.8516            | 0.8897             | 6.00
l2       | saga       | 1       | 1000     | 0.8516            | 0.8897             | 6.00
l2       | liblinear  | 1       | 200      | 0.8484            | 0.8863             | 6.00
l2       | liblinear  | 1       | 500      | 0.8484            | 0.8863             | 6.00
l2       | liblinear  | 1       | 1000     | 0.8484            | 0.8863             | 6.00
l2       | liblinear  | 0.1     | 200      | 0.8452            | 0.8864             | 6.00
l2       | liblinear  | 0.1     | 500      | 0.8452            | 0.8864             | 6.00
l2       | liblinear  | 0.1     | 1000     | 0.8452            | 0.8864             | 6.00
l1       | liblinear  | 1       | 200      | 0.8419            | 0.8813             | 4.80

  -> MELHOR ESCOLHA PARA 'VERTEBRAL_COLUMN': {'penalty': 'l2', 'C': 1, 'max_iter': 200, 'solver': 'saga'} (*)