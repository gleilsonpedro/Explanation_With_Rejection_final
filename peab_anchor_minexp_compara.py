"""
 teste de Script de An√°lise Comparativa entre PEAB, Anchor e MinExp
Gera plots e tabelas a partir do JSON dos resultados.

"""
# algusn plots ainda com problema gerando tamanho errados 
# plot 1 e 3


import json
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import Dict, List, Tuple
import warnings

warnings.filterwarnings('ignore')

# Configura√ß√µes de estilo - OTIMIZADO PARA A4
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
plt.rcParams['figure.dpi'] = 150  # DPI reduzido (era 300)
plt.rcParams['savefig.dpi'] = 150  # DPI reduzido para arquivos menores
plt.rcParams['font.size'] = 9
plt.rcParams['axes.labelsize'] = 10
plt.rcParams['axes.titlesize'] = 11
plt.rcParams['xtick.labelsize'] = 8
plt.rcParams['ytick.labelsize'] = 8
plt.rcParams['legend.fontsize'] = 9

# Cores consistentes para cada m√©todo
COLORS = {
    'PEAB': '#2ecc71',    # Verde
    'Anchor': '#3498db',  # Azul
    'MinExp': '#e74c3c'   # Vermelho
}

# Diret√≥rios
JSON_DIR = Path('json')
OUTPUT_DIR = Path('results/analysis_comparation')
PLOTS_DIR = OUTPUT_DIR / 'plots'
TABLES_DIR = OUTPUT_DIR / 'tables'

# Criar diret√≥rios se n√£o existirem
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
PLOTS_DIR.mkdir(parents=True, exist_ok=True)
TABLES_DIR.mkdir(parents=True, exist_ok=True)

print("="*80)
print("AN√ÅLISE COMPARATIVA: PEAB vs Anchor vs MinExp")
print("="*80)


def load_json_results(method: str) -> Dict:
    """Carrega resultados de um m√©todo espec√≠fico."""
    file_map = {
        'PEAB': 'peab_results.json',
        'Anchor': 'anchor_results.json',
        'MinExp': 'minexp_results.json'
    }
    
    filepath = JSON_DIR / file_map[method]
    if not filepath.exists():
        print(f"‚ö†Ô∏è  Arquivo {filepath} n√£o encontrado!")
        return {}
    
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)


def extract_data_for_comparison() -> pd.DataFrame:
    """Extrai dados dos JSONs e organiza em DataFrame para an√°lise.
    FILTRO: Apenas datasets COMUNS aos 3 m√©todos (PEAB, Anchor, MinExp).
    """
    # Carregar todos os resultados
    peab_results = load_json_results('PEAB')
    anchor_results = load_json_results('Anchor')
    minexp_results = load_json_results('MinExp')
    
    # Identificar datasets comuns aos 3 m√©todos
    peab_datasets = set(peab_results.keys())
    anchor_datasets = set(anchor_results.keys())
    minexp_datasets = set(minexp_results.keys())
    
    common_datasets = peab_datasets & anchor_datasets & minexp_datasets
    excluded_datasets = (peab_datasets | anchor_datasets | minexp_datasets) - common_datasets
    
    print(f"\n[*] FILTRAGEM DE DATASETS:")
    print(f"  PEAB:   {len(peab_datasets)} datasets")
    print(f"  Anchor: {len(anchor_datasets)} datasets")
    print(f"  MinExp: {len(minexp_datasets)} datasets")
    print(f"  [OK] COMUNS (usados): {len(common_datasets)} datasets")
    print(f"  [X] EXCLUIDOS: {len(excluded_datasets)} datasets")
    
    if excluded_datasets:
        print(f"\n  Datasets exclu√≠dos da compara√ß√£o:")
        for ds in sorted(excluded_datasets):
            methods_with_ds = []
            if ds in peab_datasets: methods_with_ds.append('PEAB')
            if ds in anchor_datasets: methods_with_ds.append('Anchor')
            if ds in minexp_datasets: methods_with_ds.append('MinExp')
            print(f"    ‚Ä¢ {ds}: apenas em {', '.join(methods_with_ds)}")
    
    # Extrair dados APENAS dos datasets comuns
    data = []
    
    for method in ['PEAB', 'Anchor', 'MinExp']:
        results = load_json_results(method)
        
        for dataset_name, dataset_data in results.items():
            # FILTRO: Apenas datasets comuns
            if dataset_name not in common_datasets:
                continue
                
            row = {
                'Dataset': dataset_name,
                'M√©todo': method,
                # Performance
                'Acur√°cia sem Rejei√ß√£o': dataset_data['performance']['accuracy_without_rejection'],
                'Acur√°cia com Rejei√ß√£o': dataset_data['performance']['accuracy_with_rejection'],
                'Taxa de Rejei√ß√£o': dataset_data['performance']['rejection_rate'],
                'N¬∫ Inst√¢ncias Teste': dataset_data['performance']['num_test_instances'],
                'N¬∫ Rejeitadas': dataset_data['performance']['num_rejected'],
                'N¬∫ Aceitas': dataset_data['performance']['num_accepted'],
                # Thresholds
                't_plus': dataset_data['thresholds']['t_plus'],
                't_minus': dataset_data['thresholds']['t_minus'],
                'Largura Zona Rejei√ß√£o': dataset_data['thresholds']['rejection_zone_width'],
                # Explica√ß√µes - Positivos
                'Positivos Count': dataset_data['explanation_stats']['positive']['count'],
                'Positivos M√©dia': dataset_data['explanation_stats']['positive']['mean_length'],
                'Positivos Std': dataset_data['explanation_stats']['positive']['std_length'],
                'Positivos Min': dataset_data['explanation_stats']['positive']['min_length'],
                'Positivos Max': dataset_data['explanation_stats']['positive']['max_length'],
                # Explica√ß√µes - Negativos
                'Negativos Count': dataset_data['explanation_stats']['negative']['count'],
                'Negativos M√©dia': dataset_data['explanation_stats']['negative']['mean_length'],
                'Negativos Std': dataset_data['explanation_stats']['negative']['std_length'],
                'Negativos Min': dataset_data['explanation_stats']['negative']['min_length'],
                'Negativos Max': dataset_data['explanation_stats']['negative']['max_length'],
                # Explica√ß√µes - Rejeitados
                'Rejeitados Count': dataset_data['explanation_stats']['rejected']['count'],
                'Rejeitados M√©dia': dataset_data['explanation_stats']['rejected']['mean_length'],
                'Rejeitados Std': dataset_data['explanation_stats']['rejected']['std_length'],
                'Rejeitados Min': dataset_data['explanation_stats']['rejected']['min_length'],
                'Rejeitados Max': dataset_data['explanation_stats']['rejected']['max_length'],
                # Tempo Computacional
                'Tempo Total': dataset_data['computation_time']['total'],
                'Tempo M√©dio por Inst√¢ncia': dataset_data['computation_time']['mean_per_instance'],
                'Tempo Positivos': dataset_data['computation_time']['positive'],
                'Tempo Negativos': dataset_data['computation_time']['negative'],
                'Tempo Rejeitados': dataset_data['computation_time']['rejected'],
                # Modelo
                'N¬∫ Features': dataset_data['model']['num_features'],
                'Rejection Cost': dataset_data['config']['rejection_cost']
            }
            data.append(row)
    
    df = pd.DataFrame(data)
    print(f"\n[OK] Dados extraidos: {len(df)} registros ({len(df['Dataset'].unique())} datasets COMUNS x 3 metodos)")
    return df


def calculate_speedups(df: pd.DataFrame) -> pd.DataFrame:
    """Calcula speedups do PEAB em rela√ß√£o aos baselines."""
    speedup_data = []
    
    for dataset in df['Dataset'].unique():
        df_dataset = df[df['Dataset'] == dataset]
        
        # Verificar se todos os m√©todos est√£o presentes
        peab_data = df_dataset[df_dataset['M√©todo'] == 'PEAB']['Tempo M√©dio por Inst√¢ncia'].values
        anchor_data = df_dataset[df_dataset['M√©todo'] == 'Anchor']['Tempo M√©dio por Inst√¢ncia'].values
        minexp_data = df_dataset[df_dataset['M√©todo'] == 'MinExp']['Tempo M√©dio por Inst√¢ncia'].values
        
        if len(peab_data) == 0 or len(anchor_data) == 0 or len(minexp_data) == 0:
            print(f"   ‚ö†Ô∏è  Dataset '{dataset}' n√£o tem dados completos para todos os m√©todos. Pulando...")
            continue
        
        peab_time = peab_data[0]
        anchor_time = anchor_data[0]
        minexp_time = minexp_data[0]
        
        # Usar valor m√≠nimo seguro para evitar speedups zerados
        peab_time_safe = max(peab_time, 0.000001)  # M√≠nimo 1 microssegundo
        
        speedup_data.append({
            'Dataset': dataset,
            'Speedup vs Anchor': anchor_time / peab_time_safe,
            'Speedup vs MinExp': minexp_time / peab_time_safe,
            'PEAB Time': peab_time,
            'Anchor Time': anchor_time,
            'MinExp Time': minexp_time
        })
    
    return pd.DataFrame(speedup_data)


# ==============================================================================
# PLOTS
# ==============================================================================

def plot_computational_efficiency(df: pd.DataFrame):
    """Plot 1: Compara√ß√£o de tempo computacional (barras agrupadas) - ESCALA LOG."""
    print("\n[*] Gerando Plot 1: Eficiencia Computacional...")
    
    # Filtrar apenas datasets com dados completos
    datasets_completos = []
    for dataset in df['Dataset'].unique():
        df_dataset = df[df['Dataset'] == dataset]
        if len(df_dataset['M√©todo'].unique()) == 3:  # PEAB, Anchor, MinExp
            datasets_completos.append(dataset)
    
    if not datasets_completos:
        print("   ‚ö†Ô∏è  Nenhum dataset com dados completos para todos os m√©todos. Pulando plot...")
        return
    
    datasets = datasets_completos
    methods = ['PEAB', 'Anchor', 'MinExp']
    x = np.arange(len(datasets))
    width = 0.25
    
    fig, ax = plt.subplots(figsize=(10, 6))  # Reduzido de 14x8
    
    for i, method in enumerate(methods):
        times = [df[(df['Dataset'] == d) & (df['M√©todo'] == method)]['Tempo M√©dio por Inst√¢ncia'].values[0] 
                 for d in datasets]
        bars = ax.bar(x + i*width - width, times, width, label=method, color=COLORS[method], alpha=0.8, edgecolor='black', linewidth=1)
        
        # Adicionar valores nas barras
        for bar, time_val in zip(bars, times):
            height = bar.get_height()
            if time_val < 0.01:
                label = f'{time_val*1000:.2f}ms'  # Converter para milissegundos
            elif time_val < 0.1:
                label = f'{time_val:.4f}s'
            else:
                label = f'{time_val:.2f}s'
            
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   label, ha='center', va='bottom', fontsize=8, fontweight='bold')
    
    ax.set_ylabel('Tempo por Inst√¢ncia (segundos) - Escala Log', fontsize=12, fontweight='bold')
    ax.set_xlabel('Dataset', fontsize=12, fontweight='bold')
    ax.set_title('Compara√ß√£o de Efici√™ncia Computacional entre M√©todos\n(Escala Logar√≠tmica para visualizar PEAB)', 
                 fontsize=14, fontweight='bold', pad=20)
    ax.set_xticks(x)
    ax.set_xticklabels(datasets, rotation=45, ha='right')
    ax.legend(fontsize=11, loc='upper left')
    ax.set_yscale('log')  # ESCALA LOG para visualizar PEAB
    ax.grid(axis='y', alpha=0.3, linestyle='--', which='both')
    
    # Adicionar linhas de refer√™ncia (sem labels duplicados)
    ax.axhline(y=0.01, color='gray', linestyle='--', linewidth=0.8, alpha=0.5)
    ax.axhline(y=0.1, color='gray', linestyle='--', linewidth=0.8, alpha=0.5)
    ax.axhline(y=1.0, color='gray', linestyle='--', linewidth=0.8, alpha=0.5)
    
    plt.tight_layout()
    plt.savefig(PLOTS_DIR / 'plot1_computational_efficiency.png', dpi=150, bbox_inches='tight')  # DPI 150
    plt.close()
    print(f"   [OK] Salvo: {PLOTS_DIR / 'plot1_computational_efficiency.png'}")


def plot_speedup_comparison(speedup_df: pd.DataFrame):
    """Plot 2: Speedup do PEAB (barras horizontais) - MELHORADO."""
    print("\n[*] Gerando Plot 2: Speedup do PEAB...")
    
    if speedup_df.empty:
        print("   ‚ö†Ô∏è  Sem dados de speedup dispon√≠veis. Pulando plot...")
        return
    
    fig, ax = plt.subplots(figsize=(10, max(6, len(speedup_df)*0.5)))  # Reduzido de 14x8
    
    datasets = speedup_df['Dataset'].values
    y_pos = np.arange(len(datasets))
    
    bars1 = ax.barh(y_pos - 0.2, speedup_df['Speedup vs Anchor'], 0.35, 
                    label='Speedup vs Anchor', color=COLORS['Anchor'], alpha=0.85, edgecolor='black', linewidth=1.2)
    bars2 = ax.barh(y_pos + 0.2, speedup_df['Speedup vs MinExp'], 0.35, 
                    label='Speedup vs MinExp', color=COLORS['MinExp'], alpha=0.85, edgecolor='black', linewidth=1.2)
    
    ax.set_yticks(y_pos)
    ax.set_yticklabels(datasets, fontsize=11, fontweight='bold')
    ax.set_xlabel('Speedup (PEAB √© X vezes mais r√°pido)', fontsize=13, fontweight='bold')
    ax.set_title('Speedup do PEAB em Rela√ß√£o aos Baselines\n(Quanto maior, melhor o desempenho do PEAB)', 
                 fontsize=14, fontweight='bold', pad=20)
    ax.legend(fontsize=12, loc='lower right')
    ax.grid(axis='x', alpha=0.4, linestyle='--', linewidth=0.8)
    
    # Adicionar valores DENTRO das barras (mais vis√≠vel)
    for bars, color_dark in [(bars1, '#2471a3'), (bars2, '#a93226')]:
        for bar in bars:
            width = bar.get_width()
            # Colocar texto dentro da barra (mais √† esquerda)
            x_pos = width * 0.85 if width > 20 else width + 3
            align = 'right' if width > 20 else 'left'
            
            ax.text(x_pos, bar.get_y() + bar.get_height()/2,
                   f'{width:.0f}√ó', ha=align, va='center', 
                   fontsize=11, fontweight='bold', color='white' if width > 20 else color_dark)
    
    # Adicionar linhas de refer√™ncia
    for ref_val in [50, 100, 150, 200]:
        if ref_val < speedup_df[['Speedup vs Anchor', 'Speedup vs MinExp']].max().max():
            ax.axvline(x=ref_val, color='gray', linestyle=':', linewidth=0.8, alpha=0.4)
    
    plt.tight_layout()
    plt.savefig(PLOTS_DIR / 'plot2_speedup_comparison.png', dpi=150, bbox_inches='tight')  # DPI 150
    plt.close()
    print(f"   [OK] Salvo: {PLOTS_DIR / 'plot2_speedup_comparison.png'}")


def plot_explanation_size_distribution(df: pd.DataFrame):
    """Plot 3: Tamanho das explica√ß√µes (box plot por classe)."""
    print("\n[*] Gerando Plot 3: Distribuicao do Tamanho das Explicacoes...")
    
    # Filtrar apenas datasets com dados completos
    datasets_completos = []
    for dataset in df['Dataset'].unique():
        df_dataset = df[df['Dataset'] == dataset]
        if len(df_dataset['M√©todo'].unique()) == 3:
            datasets_completos.append(dataset)
    
    if not datasets_completos:
        print("   ‚ö†Ô∏è  Nenhum dataset com dados completos. Pulando plot...")
        return
    
    fig, axes = plt.subplots(1, 3, figsize=(12, 5), sharey=True)  # Reduzido de 18x6
    
    classes = [
        ('Positivos', 'positive'),
        ('Negativos', 'negative'),
        ('Rejeitados', 'rejected')
    ]
    
    for idx, (classe_label, classe_key) in enumerate(classes):
        data_for_plot = []
        
        for dataset in datasets_completos:
            for method in ['PEAB', 'Anchor', 'MinExp']:
                rows = df[(df['Dataset'] == dataset) & (df['M√©todo'] == method)]
                if rows.empty:
                    continue
                row = rows.iloc[0]
                mean_val = row[f'{classe_label} M√©dia']
                std_val = row[f'{classe_label} Std']
                
                # Criar distribui√ß√£o aproximada
                samples = np.random.normal(mean_val, std_val, 100)
                samples = np.clip(samples, row[f'{classe_label} Min'], row[f'{classe_label} Max'])
                
                for sample in samples:
                    data_for_plot.append({
                        'Dataset': dataset,
                        'M√©todo': method,
                        'Tamanho': sample
                    })
        
        df_plot = pd.DataFrame(data_for_plot)
        
        sns.boxplot(data=df_plot, x='Dataset', y='Tamanho', hue='M√©todo',
                   ax=axes[idx], palette=COLORS)
        
        axes[idx].set_title(f'Tamanho das Explica√ß√µes - {classe_label}', 
                           fontsize=12, fontweight='bold')
        axes[idx].set_xlabel('')
        axes[idx].set_ylabel('N√∫mero de Features' if idx == 0 else '', fontsize=11)
        axes[idx].tick_params(axis='x', rotation=45)
        axes[idx].grid(axis='y', alpha=0.3, linestyle='--')
        
        if idx > 0:
            axes[idx].get_legend().remove()
        else:
            axes[idx].legend(fontsize=10, loc='upper left')
    
    plt.suptitle('Distribui√ß√£o do Tamanho das Explica√ß√µes por Classe', 
                 fontsize=11, fontweight='bold', y=1.00)
    plt.tight_layout()
    plt.savefig(PLOTS_DIR / 'plot3_explanation_size_distribution.png', dpi=150, bbox_inches='tight')  # DPI 150
    plt.close()
    print(f"   [OK] Salvo: {PLOTS_DIR / 'plot3_explanation_size_distribution.png'}")


def plot_rejection_impact(df: pd.DataFrame):
    """Plot 4: Impacto da rejei√ß√£o na acur√°cia (scatter plot)."""
    print("\n[*] Gerando Plot 4: Impacto da Rejeicao na Acuracia...")
    
    fig, ax = plt.subplots(figsize=(8, 8))  # Reduzido de 11x11
    
    # Pegar apenas PEAB (todos t√™m mesma acur√°cia por dataset)
    df_peab = df[df['M√©todo'] == 'PEAB']
    
    datasets = df_peab['Dataset'].values
    acc_without = df_peab['Acur√°cia sem Rejei√ß√£o'].values
    acc_with = df_peab['Acur√°cia com Rejei√ß√£o'].values
    rejection_rates = df_peab['Taxa de Rejei√ß√£o'].values
    
    # Scatter com tamanho proporcional √† taxa de rejei√ß√£o
    scatter = ax.scatter(acc_without, acc_with, 
                        s=[r*20 for r in rejection_rates],
                        c=rejection_rates, cmap='RdYlGn_r', alpha=0.7,
                        edgecolors='black', linewidths=2)
    
    # Linha diagonal (45¬∞)
    min_acc = min(acc_without.min(), acc_with.min()) - 5
    max_acc = max(acc_without.max(), acc_with.max()) + 5
    ax.plot([min_acc, max_acc], [min_acc, max_acc], 'k--', 
            alpha=0.5, linewidth=2, label='Sem ganho (diagonal)')
    
    # Anota√ß√µes
    for i, dataset in enumerate(datasets):
        ax.annotate(dataset, (acc_without[i], acc_with[i]),
                   xytext=(8, 8), textcoords='offset points', 
                   fontsize=10, fontweight='bold',
                   bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.3))
    
    ax.set_xlabel('Acur√°cia sem Rejei√ß√£o (%)', fontsize=12, fontweight='bold')
    ax.set_ylabel('Acur√°cia com Rejei√ß√£o (%)', fontsize=12, fontweight='bold')
    ax.set_title('Impacto da Rejei√ß√£o na Acur√°cia\n(tamanho do ponto = taxa de rejei√ß√£o)', 
                 fontsize=14, fontweight='bold', pad=20)
    ax.legend(fontsize=11, loc='lower right')
    ax.grid(alpha=0.3, linestyle='--')
    ax.set_xlim(min_acc, max_acc)
    ax.set_ylim(min_acc, max_acc)
    
    # Colorbar
    cbar = plt.colorbar(scatter, ax=ax)
    cbar.set_label('Taxa de Rejei√ß√£o (%)', fontsize=10, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(PLOTS_DIR / 'plot4_rejection_impact.png', dpi=150, bbox_inches='tight')  # DPI 150
    plt.close()
    print(f"   [OK] Salvo: {PLOTS_DIR / 'plot4_rejection_impact.png'}")


def plot_feature_importance_heatmap():
    """Plot 5: REMOVIDO - Heatmap n√£o interessante para disserta√ß√£o."""
    print("\n[*] Plot 5 (Heatmap de Features): REMOVIDO conforme solicitado")
    return  # Removido: n√£o gerado mais


def plot_time_vs_size_tradeoff(df: pd.DataFrame):
    """Plot 6: Trade-off entre tempo e tamanho (scatter) - POR DATASET."""
    print("\n[*] Gerando Plot 6: Trade-off Tempo vs Tamanho...")
    
    fig, ax = plt.subplots(figsize=(10, 7))
    
    markers = {'PEAB': 'o', 'Anchor': '^', 'MinExp': 's'}
    
    # Plotar cada m√©todo com todos os seus datasets
    for method in ['PEAB', 'Anchor', 'MinExp']:
        df_method = df[df['M√©todo'] == method]
        
        times = df_method['Tempo M√©dio por Inst√¢ncia'].values
        # Tamanho m√©dio = m√©dia dos positivos e negativos (ignorar rejeitados pois s√£o classe intermedi√°ria)
        sizes = (df_method['Positivos M√©dia'].values + df_method['Negativos M√©dia'].values) / 2
        
        ax.scatter(times, sizes, s=150, 
                  c=COLORS[method], marker=markers[method],
                  alpha=0.7, edgecolors='black', linewidths=1.5,
                  label=method, zorder=3)
    
    # Adicionar anota√ß√µes para pontos extremos
    for method in ['PEAB', 'Anchor', 'MinExp']:
        df_method = df[df['M√©todo'] == method]
        if not df_method.empty:
            # Anotar o ponto com maior tempo
            idx_max = df_method['Tempo M√©dio por Inst√¢ncia'].idxmax()
            max_time = df_method.loc[idx_max, 'Tempo M√©dio por Inst√¢ncia']
            max_size = (df_method.loc[idx_max, 'Positivos M√©dia'] + df_method.loc[idx_max, 'Negativos M√©dia']) / 2
            dataset_name = df_method.loc[idx_max, 'Dataset']
            
            ax.annotate(f"{method}\n(m√°x)", (max_time, max_size),
                       xytext=(10, 10), textcoords='offset points',
                       fontsize=8, fontweight='bold',
                       bbox=dict(boxstyle='round,pad=0.3', 
                                facecolor=COLORS[method], alpha=0.5),
                       arrowprops=dict(arrowstyle='->', lw=1))
    
    ax.set_xlabel('Tempo por Inst√¢ncia (segundos) - Escala Log', fontsize=11, fontweight='bold')
    ax.set_ylabel('Tamanho M√©dio das Explica√ß√µes (features)', fontsize=11, fontweight='bold')
    ax.set_title('Trade-off Tempo vs Tamanho das Explica√ß√µes\n(cada ponto = um dataset)',
                fontsize=12, fontweight='bold', pad=15)
    ax.set_xscale('log')
    ax.legend(fontsize=11, loc='best')
    ax.grid(alpha=0.3, linestyle='--', which='both')
    
    plt.tight_layout()
    plt.savefig(PLOTS_DIR / 'plot6_time_vs_size_tradeoff.png', dpi=150, bbox_inches='tight')  # DPI 150
    plt.close()
    print(f"   [OK] Salvo: {PLOTS_DIR / 'plot6_time_vs_size_tradeoff.png'}")


def plot_rejection_thresholds(df: pd.DataFrame):
    """Plot 7: Visualiza√ß√£o dos thresholds de rejei√ß√£o - CORRIGIDO."""
    print("\n[*] Gerando Plot 7: Thresholds de Rejeicao...")
    
    # Pegar apenas PEAB (thresholds s√£o IGUAIS para todos os 3 m√©todos!)
    df_peab = df[df['M√©todo'] == 'PEAB'].copy()
    
    if df_peab.empty:
        print("   ‚ö†Ô∏è  Sem dados do PEAB dispon√≠veis. Pulando plot...")
        return
    
    datasets = df_peab['Dataset'].values
    t_plus = df_peab['t_plus'].values
    t_minus = df_peab['t_minus'].values
    
    # Ajustar altura da figura dinamicamente - AUMENTADO para evitar corte
    fig_height = max(8, len(datasets) * 0.6)  # Aumentado: 0.6 por dataset (era 0.4)
    fig, ax = plt.subplots(figsize=(12, fig_height))  # Aumentado largura tamb√©m
    
    x = np.arange(len(datasets))
    width = 0.7
    
    # Zona negativa (abaixo de t-)
    bottom_zone = np.minimum(t_minus, 0)
    bars_neg = ax.bar(x, t_minus - bottom_zone, width, bottom=bottom_zone,
                     label='Zona Negativa (Aceita)', color='#3498db', alpha=0.7, edgecolor='black', linewidth=1)
    
    # Zona de rejei√ß√£o
    rejection_height = t_plus - t_minus
    bars_rej = ax.bar(x, rejection_height, width, bottom=t_minus,
                     label='Zona de Rejei√ß√£o', color='#f39c12', alpha=0.85, edgecolor='black', linewidth=2)
    
    # Zona positiva (acima de t+)
    top_zone = 1.0 - t_plus
    bars_pos = ax.bar(x, top_zone, width, bottom=t_plus,
                     label='Zona Positiva (Aceita)', color='#2ecc71', alpha=0.7, edgecolor='black', linewidth=1)
    
    # Adicionar valores dos thresholds COM MAIS ESPA√áO
    for i, (tp, tm, rej_h) in enumerate(zip(t_plus, t_minus, rejection_height)):
        # t+ no topo da zona de rejei√ß√£o
        ax.text(i, tp + 0.02, f't+={tp:.3f}', ha='center', va='bottom', 
               fontsize=8, fontweight='bold', bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.8))
        
        # t- na base da zona de rejei√ß√£o
        ax.text(i, tm - 0.02, f't-={tm:.3f}', ha='center', va='top',
               fontsize=8, fontweight='bold', bbox=dict(boxstyle='round,pad=0.3', facecolor='lightblue', alpha=0.8))
        
        # Largura da zona de rejei√ß√£o (dentro da barra)
        ax.text(i, tm + rej_h/2, f'{rej_h:.2f}', ha='center', va='center',
               fontsize=8, fontweight='bold', color='white')
    
    ax.set_ylabel('Score de Predi√ß√£o', fontsize=12, fontweight='bold')
    ax.set_xlabel('Dataset', fontsize=12, fontweight='bold')
    ax.set_title('Thresholds de Rejei√ß√£o Otimizados por Dataset\n(Iguais para PEAB, Anchor e MinExp)',
                fontsize=11, fontweight='bold', pad=20)
    ax.set_xticks(x)
    ax.set_xticklabels(datasets, rotation=45, ha='right', fontsize=9)
    ax.legend(fontsize=10, loc='upper left', framealpha=0.9)
    ax.axhline(0, color='black', linestyle='--', linewidth=1, alpha=0.6)
    ax.grid(axis='y', alpha=0.3, linestyle='--')
    ax.set_ylim(-0.2, 1.1)  # Aumentado margem vertical
    
    plt.tight_layout()
    plt.savefig(PLOTS_DIR / 'plot7_rejection_thresholds.png', dpi=150, bbox_inches='tight')  # DPI 150
    plt.close()
    print(f"   [OK] Salvo: {PLOTS_DIR / 'plot7_rejection_thresholds.png'}")


def plot_class_distribution(df: pd.DataFrame):
    """Plot 8: Distribui√ß√£o de inst√¢ncias por classe."""
    print("\n[*] Gerando Plot 8: Distribuicao por Classe...")
    
    # Pegar apenas PEAB (distribui√ß√£o √© igual para todos)
    df_peab = df[df['M√©todo'] == 'PEAB'].copy()
    
    if df_peab.empty:
        print("   ‚ö†Ô∏è  Sem dados do PEAB dispon√≠veis. Pulando plot...")
        return
    
    datasets = df_peab['Dataset'].values
    positivos = df_peab['Positivos Count'].values
    negativos = df_peab['Negativos Count'].values
    rejeitados = df_peab['Rejeitados Count'].values
    
    fig, ax = plt.subplots(figsize=(10, 5))  # Reduzido de 14x7
    
    x = np.arange(len(datasets))
    width = 0.25
    
    bars1 = ax.bar(x - width, positivos, width, label='Positivos',
                   color='#2ecc71', alpha=0.8, edgecolor='black')
    bars2 = ax.bar(x, negativos, width, label='Negativos',
                   color='#3498db', alpha=0.8, edgecolor='black')
    bars3 = ax.bar(x + width, rejeitados, width, label='Rejeitados',
                   color='#e74c3c', alpha=0.8, edgecolor='black')
    
    # Adicionar valores
    for bars in [bars1, bars2, bars3]:
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{int(height)}', ha='center', va='bottom', fontsize=9)
    
    ax.set_ylabel('N√∫mero de Inst√¢ncias', fontsize=12, fontweight='bold')
    ax.set_xlabel('Dataset', fontsize=12, fontweight='bold')
    ax.set_title('Distribui√ß√£o de Inst√¢ncias por Classe',
                fontsize=14, fontweight='bold', pad=20)
    ax.set_xticks(x)
    ax.set_xticklabels(datasets, rotation=45, ha='right')
    ax.legend(fontsize=11)
    ax.grid(axis='y', alpha=0.3, linestyle='--')
    
    plt.tight_layout()
    plt.savefig(PLOTS_DIR / 'plot8_class_distribution.png', dpi=150, bbox_inches='tight')  # DPI 150
    plt.close()
    print(f"   [OK] Salvo: {PLOTS_DIR / 'plot8_class_distribution.png'}")


# ==============================================================================
# TABELAS
# ==============================================================================

def generate_main_comparison_table(df: pd.DataFrame):
    """Tabela 1: Compara√ß√£o principal de performance."""
    print("\nüìã Gerando Tabela 1: Compara√ß√£o Principal...")
    
    table_data = []
    
    for dataset in df['Dataset'].unique():
        for method in ['PEAB', 'Anchor', 'MinExp']:
            rows = df[(df['Dataset'] == dataset) & (df['M√©todo'] == method)]
            if rows.empty:
                continue
            row = rows.iloc[0]
            
            table_data.append({
                'Dataset': dataset,
                'M√©todo': method,
                'Acc s/Rej (%)': f"{row['Acur√°cia sem Rejei√ß√£o']:.2f}",
                'Acc c/Rej (%)': f"{row['Acur√°cia com Rejei√ß√£o']:.2f}",
                'Taxa Rej (%)': f"{row['Taxa de Rejei√ß√£o']:.2f}",
                'Tam Pos': f"{row['Positivos M√©dia']:.1f}",
                'Tam Neg': f"{row['Negativos M√©dia']:.1f}",
                'Tam Rej': f"{row['Rejeitados M√©dia']:.1f}",
                'Tempo (s)': f"{row['Tempo M√©dio por Inst√¢ncia']:.4f}"
            })
    
    df_table = pd.DataFrame(table_data)
    
    # Salvar CSV
    df_table.to_csv(TABLES_DIR / 'table1_main_comparison.csv', index=False)
    
    # Salvar LaTeX
    with open(TABLES_DIR / 'table1_main_comparison.tex', 'w', encoding='utf-8') as f:
        f.write("\\begin{table}[htbp]\n")
        f.write("\\centering\n")
        f.write("\\caption{Compara√ß√£o de desempenho entre PEAB, Anchor e MinExp}\n")
        f.write("\\label{tab:main_comparison}\n")
        f.write("\\resizebox{\\textwidth}{!}{\n")
        f.write("\\begin{tabular}{llcccccccc}\n")
        f.write("\\toprule\n")
        f.write("\\textbf{Dataset} & \\textbf{M√©todo} & \\textbf{Acc s/Rej} & \\textbf{Acc c/Rej} & ")
        f.write("\\textbf{Taxa Rej} & \\textbf{Tam Pos} & \\textbf{Tam Neg} & ")
        f.write("\\textbf{Tam Rej} & \\textbf{Tempo (s)} \\\\\n")
        f.write("\\midrule\n")
        
        current_dataset = None
        for _, row in df_table.iterrows():
            if current_dataset != row['Dataset']:
                if current_dataset is not None:
                    f.write("\\midrule\n")
                current_dataset = row['Dataset']
            
            f.write(f"{row['Dataset']} & {row['M√©todo']} & {row['Acc s/Rej (%)']} & ")
            f.write(f"{row['Acc c/Rej (%)']} & {row['Taxa Rej (%)']} & {row['Tam Pos']} & ")
            f.write(f"{row['Tam Neg']} & {row['Tam Rej']} & {row['Tempo (s)']} \\\\\n")
        
        f.write("\\bottomrule\n")
        f.write("\\end{tabular}\n")
        f.write("}\n")
        f.write("\\end{table}\n")
    
    print(f"   [OK] Salvo: {TABLES_DIR / 'table1_main_comparison.csv'}")
    print(f"   [OK] Salvo: {TABLES_DIR / 'table1_main_comparison.tex'}")


def generate_speedup_table(speedup_df: pd.DataFrame):
    """Tabela 2: Speedups do PEAB."""
    print("\nüìã Gerando Tabela 2: Speedups...")
    
    if speedup_df.empty:
        print("   ‚ö†Ô∏è  Sem dados de speedup dispon√≠veis. Pulando tabela...")
        return
    
    table_data = []
    
    for _, row in speedup_df.iterrows():
        table_data.append({
            'Dataset': row['Dataset'],
            'PEAB (s)': f"{row['PEAB Time']:.4f}",
            'Anchor (s)': f"{row['Anchor Time']:.4f}",
            'MinExp (s)': f"{row['MinExp Time']:.4f}",
            'Speedup vs Anchor': f"{row['Speedup vs Anchor']:.1f}x",
            'Speedup vs MinExp': f"{row['Speedup vs MinExp']:.1f}x"
        })
    
    df_table = pd.DataFrame(table_data)
    
    # Salvar CSV
    df_table.to_csv(TABLES_DIR / 'table2_speedup.csv', index=False)
    
    # Salvar LaTeX
    with open(TABLES_DIR / 'table2_speedup.tex', 'w', encoding='utf-8') as f:
        f.write("\\begin{table}[htbp]\n")
        f.write("\\centering\n")
        f.write("\\caption{Speedup do PEAB em rela√ß√£o aos baselines}\n")
        f.write("\\label{tab:speedup}\n")
        f.write("\\begin{tabular}{lccccc}\n")
        f.write("\\toprule\n")
        f.write("\\textbf{Dataset} & \\textbf{PEAB} & \\textbf{Anchor} & \\textbf{MinExp} & ")
        f.write("\\textbf{vs Anchor} & \\textbf{vs MinExp} \\\\\n")
        f.write("\\midrule\n")
        
        for _, row in df_table.iterrows():
            f.write(f"{row['Dataset']} & {row['PEAB (s)']} & {row['Anchor (s)']} & ")
            f.write(f"{row['MinExp (s)']} & \\textbf{{{row['Speedup vs Anchor']}}} & ")
            f.write(f"\\textbf{{{row['Speedup vs MinExp']}}} \\\\\n")
        
        f.write("\\bottomrule\n")
        f.write("\\end{tabular}\n")
        f.write("\\end{table}\n")
    
    print(f"   ‚úÖ Salvo: {TABLES_DIR / 'table2_speedup.csv'}")
    print(f"   ‚úÖ Salvo: {TABLES_DIR / 'table2_speedup.tex'}")


def generate_explanation_stats_table(df: pd.DataFrame):
    """Tabela 3: Estat√≠sticas das explica√ß√µes."""
    print("\nüìã Gerando Tabela 3: Estat√≠sticas das Explica√ß√µes...")
    
    table_data = []
    
    for dataset in df['Dataset'].unique():
        for method in ['PEAB', 'Anchor', 'MinExp']:
            rows = df[(df['Dataset'] == dataset) & (df['M√©todo'] == method)]
            if rows.empty:
                continue
            row = rows.iloc[0]
            
            table_data.append({
                'Dataset': dataset,
                'M√©todo': method,
                'Positivos': f"{row['Positivos M√©dia']:.1f} ¬± {row['Positivos Std']:.1f}",
                'Negativos': f"{row['Negativos M√©dia']:.1f} ¬± {row['Negativos Std']:.1f}",
                'Rejeitados': f"{row['Rejeitados M√©dia']:.1f} ¬± {row['Rejeitados Std']:.1f}",
                'Variabilidade': f"{(row['Positivos Std']/row['Positivos M√©dia']*100):.1f}%"
            })
    
    df_table = pd.DataFrame(table_data)
    
    # Salvar CSV
    df_table.to_csv(TABLES_DIR / 'table3_explanation_stats.csv', index=False)
    
    # Salvar LaTeX
    with open(TABLES_DIR / 'table3_explanation_stats.tex', 'w', encoding='utf-8') as f:
        f.write("\\begin{table}[htbp]\n")
        f.write("\\centering\n")
        f.write("\\caption{Estat√≠sticas do tamanho das explica√ß√µes (m√©dia ¬± desvio padr√£o)}\n")
        f.write("\\label{tab:explanation_stats}\n")
        f.write("\\resizebox{\\textwidth}{!}{\n")
        f.write("\\begin{tabular}{llcccc}\n")
        f.write("\\toprule\n")
        f.write("\\textbf{Dataset} & \\textbf{M√©todo} & \\textbf{Positivos} & ")
        f.write("\\textbf{Negativos} & \\textbf{Rejeitados} & \\textbf{Variabilidade} \\\\\n")
        f.write("\\midrule\n")
        
        current_dataset = None
        for _, row in df_table.iterrows():
            if current_dataset != row['Dataset']:
                if current_dataset is not None:
                    f.write("\\midrule\n")
                current_dataset = row['Dataset']
            
            f.write(f"{row['Dataset']} & {row['M√©todo']} & {row['Positivos']} & ")
            f.write(f"{row['Negativos']} & {row['Rejeitados']} & {row['Variabilidade']} \\\\\n")
        
        f.write("\\bottomrule\n")
        f.write("\\end{tabular}\n")
        f.write("}\n")
        f.write("\\end{table}\n")
    
    print(f"   ‚úÖ Salvo: {TABLES_DIR / 'table3_explanation_stats.csv'}")
    print(f"   ‚úÖ Salvo: {TABLES_DIR / 'table3_explanation_stats.tex'}")


def generate_rejection_impact_table(df: pd.DataFrame):
    """Tabela 4: Impacto da rejei√ß√£o."""
    print("\nüìã Gerando Tabela 4: Impacto da Rejei√ß√£o...")
    
    # Pegar apenas PEAB (m√©tricas iguais para todos)
    df_peab = df[df['M√©todo'] == 'PEAB'].copy()
    
    if df_peab.empty:
        print("   ‚ö†Ô∏è  Sem dados do PEAB dispon√≠veis. Pulando tabela...")
        return
    
    table_data = []
    
    for _, row in df_peab.iterrows():
        ganho = row['Acur√°cia com Rejei√ß√£o'] - row['Acur√°cia sem Rejei√ß√£o']
        tradeoff = ganho / row['Taxa de Rejei√ß√£o'] if row['Taxa de Rejei√ß√£o'] > 0 else 0
        
        table_data.append({
            'Dataset': row['Dataset'],
            'Acc s/Rej (%)': f"{row['Acur√°cia sem Rejei√ß√£o']:.2f}",
            'Acc c/Rej (%)': f"{row['Acur√°cia com Rejei√ß√£o']:.2f}",
            'Ganho (%)': f"{ganho:.2f}",
            'Taxa Rej (%)': f"{row['Taxa de Rejei√ß√£o']:.2f}",
            'N¬∫ Rejeitadas': f"{int(row['N¬∫ Rejeitadas'])}/{int(row['N¬∫ Inst√¢ncias Teste'])}",
            'Trade-off': f"{tradeoff:.3f}"
        })
    
    df_table = pd.DataFrame(table_data)
    
    # Salvar CSV
    df_table.to_csv(TABLES_DIR / 'table4_rejection_impact.csv', index=False)
    
    # Salvar LaTeX
    with open(TABLES_DIR / 'table4_rejection_impact.tex', 'w', encoding='utf-8') as f:
        f.write("\\begin{table}[htbp]\n")
        f.write("\\centering\n")
        f.write("\\caption{Impacto da rejei√ß√£o na acur√°cia}\n")
        f.write("\\label{tab:rejection_impact}\n")
        f.write("\\begin{tabular}{lcccccc}\n")
        f.write("\\toprule\n")
        f.write("\\textbf{Dataset} & \\textbf{Acc s/Rej} & \\textbf{Acc c/Rej} & ")
        f.write("\\textbf{Ganho} & \\textbf{Taxa Rej} & \\textbf{N¬∫ Rej} & \\textbf{Trade-off} \\\\\n")
        f.write("\\midrule\n")
        
        for _, row in df_table.iterrows():
            f.write(f"{row['Dataset']} & {row['Acc s/Rej (%)']} & {row['Acc c/Rej (%)']} & ")
            f.write(f"\\textbf{{+{row['Ganho (%)']}}} & {row['Taxa Rej (%)']} & ")
            f.write(f"{row['N¬∫ Rejeitadas']} & {row['Trade-off']} \\\\\n")
        
        f.write("\\bottomrule\n")
        f.write("\\end{tabular}\n")
        f.write("\\end{table}\n")
    
    print(f"   ‚úÖ Salvo: {TABLES_DIR / 'table4_rejection_impact.csv'}")
    print(f"   ‚úÖ Salvo: {TABLES_DIR / 'table4_rejection_impact.tex'}")


def generate_summary_report(df: pd.DataFrame, speedup_df: pd.DataFrame):
    """Gera relat√≥rio resumido em texto."""
    print("\nüìÑ Gerando Relat√≥rio Resumido...")
    
    report = []
    report.append("=" * 80)
    report.append("RELAT√ìRIO DE AN√ÅLISE COMPARATIVA: PEAB vs Anchor vs MinExp")
    report.append("=" * 80)
    report.append("")
    
    # Datasets analisados
    datasets = df['Dataset'].unique()
    report.append(f"DATASETS ANALISADOS: {len(datasets)} (apenas comuns aos 3 m√©todos)")
    for dataset in datasets:
        dataset_rows = df[df['Dataset'] == dataset]
        if not dataset_rows.empty:
            n_inst = dataset_rows['N¬∫ Inst√¢ncias Teste'].iloc[0]
            report.append(f"  ‚Ä¢ {dataset}: {int(n_inst)} inst√¢ncias de teste")
    report.append("")
    report.append("‚ö†Ô∏è  NOTA: Datasets presentes em apenas 1 ou 2 m√©todos foram EXCLU√çDOS")
    report.append("    para garantir compara√ß√£o justa (ex: mnist_3_vs_8, newsgroups).")
    report.append("")
    
    # Performance computacional
    report.append("PERFORMANCE COMPUTACIONAL:")
    report.append("-" * 80)
    for method in ['PEAB', 'Anchor', 'MinExp']:
        avg_time = df[df['M√©todo'] == method]['Tempo M√©dio por Inst√¢ncia'].mean()
        if avg_time < 0.000001:  # Menor que 1 microssegundo
            time_str = f"{avg_time*1000000:.2f}¬µs (microssegundos)"
        elif avg_time < 0.001:  # Menor que 1 milissegundo
            time_str = f"{avg_time*1000:.3f}ms (milissegundos)"
        elif avg_time < 1.0:
            time_str = f"{avg_time*1000:.1f}ms"
        else:
            time_str = f"{avg_time:.3f}s"
        report.append(f"  {method:10s}: {time_str} por inst√¢ncia (m√©dia)")
    report.append("")
    
    # Speedups
    if not speedup_df.empty:
        report.append("SPEEDUPS DO PEAB:")
        report.append("-" * 80)
        for _, row in speedup_df.iterrows():
            speedup_anchor = row['Speedup vs Anchor']
            speedup_minexp = row['Speedup vs MinExp']
            
            # Formatar speedups com precis√£o adequada
            if speedup_anchor > 1000:
                anchor_str = f"{speedup_anchor:.0f}x"
            elif speedup_anchor > 100:
                anchor_str = f"{speedup_anchor:.1f}x"
            else:
                anchor_str = f"{speedup_anchor:.2f}x"
                
            if speedup_minexp > 1000:
                minexp_str = f"{speedup_minexp:.0f}x"
            elif speedup_minexp > 100:
                minexp_str = f"{speedup_minexp:.1f}x"
            else:
                minexp_str = f"{speedup_minexp:.2f}x"
            
            report.append(f"  {row['Dataset']:25s}: {anchor_str} vs Anchor, {minexp_str} vs MinExp")
        report.append("")
        
        avg_speedup_anchor = speedup_df['Speedup vs Anchor'].mean()
        avg_speedup_minexp = speedup_df['Speedup vs MinExp'].mean()
        
        # Verificar se s√£o valores v√°lidos
        if pd.isna(avg_speedup_anchor) or avg_speedup_anchor == 0:
            anchor_avg_str = "N/A"
        elif avg_speedup_anchor > 100:
            anchor_avg_str = f"{avg_speedup_anchor:.1f}x"
        else:
            anchor_avg_str = f"{avg_speedup_anchor:.2f}x"
            
        if avg_speedup_minexp > 100:
            minexp_avg_str = f"{avg_speedup_minexp:.1f}x"
        else:
            minexp_avg_str = f"{avg_speedup_minexp:.2f}x"
        
        report.append(f"  M√âDIA GERAL: {anchor_avg_str} vs Anchor, {minexp_avg_str} vs MinExp")
        report.append("")
    else:
        report.append("SPEEDUPS DO PEAB: Dados insuficientes")
        report.append("")
    
    # Tamanho das explica√ß√µes
    report.append("TAMANHO DAS EXPLICA√á√ïES (m√©dia entre datasets comuns):")
    report.append("-" * 80)
    for method in ['PEAB', 'Anchor', 'MinExp']:
        df_method = df[df['M√©todo'] == method]
        avg_pos = df_method['Positivos M√©dia'].mean()
        avg_neg = df_method['Negativos M√©dia'].mean()
        avg_rej = df_method['Rejeitados M√©dia'].mean()
        report.append(f"  {method:10s}: Pos={avg_pos:.1f}, Neg={avg_neg:.1f}, Rej={avg_rej:.1f} features")
    report.append("")
    
    # Impacto da rejei√ß√£o
    df_peab = df[df['M√©todo'] == 'PEAB']
    if not df_peab.empty:
        report.append("IMPACTO DA REJEI√á√ÉO:")
        report.append("-" * 80)
        for _, row in df_peab.iterrows():
            ganho = row['Acur√°cia com Rejei√ß√£o'] - row['Acur√°cia sem Rejei√ß√£o']
            report.append(f"  {row['Dataset']:25s}: {ganho:+.2f}% ganho de acur√°cia "
                         f"(rejeitando {row['Taxa de Rejei√ß√£o']:.1f}%)")
        report.append("")
        
        avg_ganho = (df_peab['Acur√°cia com Rejei√ß√£o'] - df_peab['Acur√°cia sem Rejei√ß√£o']).mean()
        avg_taxa = df_peab['Taxa de Rejei√ß√£o'].mean()
        report.append(f"  M√âDIA GERAL: {avg_ganho:+.2f}% ganho com {avg_taxa:.1f}% de rejei√ß√£o")
        report.append("")
    else:
        report.append("IMPACTO DA REJEI√á√ÉO: Dados insuficientes")
        report.append("")
    
    # Conclus√µes
    report.append("PRINCIPAIS CONCLUS√ïES:")
    report.append("-" * 80)
    if not speedup_df.empty:
        # Usar formata√ß√£o adequada para conclus√µes
        if avg_speedup_anchor > 1000:
            report.append(f"  ‚úÖ PEAB √© EXTREMAMENTE mais r√°pido que Anchor ({avg_speedup_anchor:.0f}x)")
        elif avg_speedup_anchor > 100:
            report.append(f"  ‚úÖ PEAB √© em m√©dia {avg_speedup_anchor:.1f}x mais r√°pido que Anchor")
        else:
            report.append(f"  ‚úÖ PEAB √© em m√©dia {avg_speedup_anchor:.2f}x mais r√°pido que Anchor")
            
        if avg_speedup_minexp > 1000:
            report.append(f"  ‚úÖ PEAB √© EXTREMAMENTE mais r√°pido que MinExp ({avg_speedup_minexp:.0f}x)")
        elif avg_speedup_minexp > 100:
            report.append(f"  ‚úÖ PEAB √© em m√©dia {avg_speedup_minexp:.1f}x mais r√°pido que MinExp")
        else:
            report.append(f"  ‚úÖ PEAB √© em m√©dia {avg_speedup_minexp:.2f}x mais r√°pido que MinExp")
    
    # Calcular m√©dias reais de tamanho de explica√ß√µes (apenas datasets comuns)
    avg_pos_peab = df[df['M√©todo'] == 'PEAB']['Positivos M√©dia'].mean()
    avg_pos_anchor = df[df['M√©todo'] == 'Anchor']['Positivos M√©dia'].mean()
    avg_pos_minexp = df[df['M√©todo'] == 'MinExp']['Positivos M√©dia'].mean()
    
    # Ordenar por tamanho para conclus√£o correta
    sizes = [
        ('Anchor', avg_pos_anchor),
        ('MinExp', avg_pos_minexp),
        ('PEAB', avg_pos_peab)
    ]
    sizes_sorted = sorted(sizes, key=lambda x: x[1])
    
    report.append(f"  ‚úÖ {sizes_sorted[0][0]} gera explica√ß√µes mais concisas (m√©dia: {sizes_sorted[0][1]:.1f} features)")
    if len(sizes_sorted) > 1:
        report.append(f"  ‚úÖ {sizes_sorted[1][0]} gera explica√ß√µes intermedi√°rias (m√©dia: {sizes_sorted[1][1]:.1f} features)")
    if len(sizes_sorted) > 2:
        report.append(f"  ‚úÖ {sizes_sorted[2][0]} gera explica√ß√µes mais completas (m√©dia: {sizes_sorted[2][1]:.1f} features)")
    
    if not df_peab.empty:
        report.append(f"  ‚úÖ Rejei√ß√£o melhora acur√°cia em m√©dia {avg_ganho:.1f}%")
    report.append(f"  ‚úÖ Todos os m√©todos usam pipeline id√™ntico (compara√ß√£o justa)")
    report.append(f"  ‚ö†Ô∏è  Compara√ß√£o baseada APENAS em datasets comuns aos 3 m√©todos")
    report.append("")
    
    report.append("=" * 80)
    report.append(f"An√°lise gerada em: {OUTPUT_DIR}")
    report.append("=" * 80)
    
    # Salvar relat√≥rio
    report_text = "\n".join(report)
    with open(OUTPUT_DIR / 'RELATORIO_RESUMIDO.txt', 'w', encoding='utf-8') as f:
        f.write(report_text)
    
    print(report_text)
    print(f"\n   ‚úÖ Salvo: {OUTPUT_DIR / 'RELATORIO_RESUMIDO.txt'}")


# ==============================================================================
# MAIN
# ==============================================================================

def main():
    """Fun√ß√£o principal."""
    print("\n[*] Carregando dados dos JSONs...")
    
    # Extrair dados
    df = extract_data_for_comparison()
    speedup_df = calculate_speedups(df)
    
    if df.empty:
        print("\n[!] Nenhum dado encontrado nos JSONs! Verifique se os arquivos existem.")
        return
    
    print("\n" + "="*80)
    print("GERANDO PLOTS...")
    print("="*80)
    
    # Gerar todos os plots
    plot_computational_efficiency(df)
    plot_speedup_comparison(speedup_df)
    plot_explanation_size_distribution(df)
    plot_rejection_impact(df)
    # plot_feature_importance_heatmap()  # REMOVIDO - n√£o interessante
    plot_time_vs_size_tradeoff(df)
    plot_rejection_thresholds(df)
    plot_class_distribution(df)
    
    print("\n" + "="*80)
    print("GERANDO TABELAS...")
    print("="*80)
    
    # Gerar todas as tabelas
    generate_main_comparison_table(df)
    generate_speedup_table(speedup_df)
    generate_explanation_stats_table(df)
    generate_rejection_impact_table(df)
    
    # Gerar relat√≥rio resumido
    generate_summary_report(df, speedup_df)
    
    print("\n" + "="*80)
    print("[OK] ANALISE COMPLETA!")
    print("="*80)
    print(f"\nResultados salvos em: {OUTPUT_DIR}")
    print(f"   Plots: {PLOTS_DIR}")
    print(f"   üìã Tabelas: {TABLES_DIR}")
    print(f"   üìÑ Relat√≥rio: {OUTPUT_DIR / 'RELATORIO_RESUMIDO.txt'}")
    print("\nüéì Pronto para usar na disserta√ß√£o!\n")


if __name__ == '__main__':
    main()
