╔══════════════════════════════════════════════════════════════════════════════╗
║                                                                              ║
║                     VALIDAÇÃO DE EXPLICABILIDADE - PEAB                      ║
║                                    Mnist                                     ║
║                                                                              ║
╚══════════════════════════════════════════════════════════════════════════════╝

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
RESUMO EXECUTIVO
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Dataset:                Mnist
  Instâncias Testadas:    503
  Features Totais:        784

  MÉTRICAS PRINCIPAIS:
    • Fidelidade:                      100.0%
    • Necessidade (feat. necessárias): 0.2%
    • Tamanho Médio:                   229.3 features
    • Taxa de Rejeição:     11.3% (57 instâncias)

  CONCLUSÃO:
    Explicações fiéis, porém contêm features redundantes.

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
METODOLOGIA DE VALIDAÇÃO
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Método Avaliado:         PEAB
  Perturbações/instância:  500

  TESTES APLICADOS:

  1. FIDELIDADE (Sufficiency) - Teste Probabilístico
     • Para cada feature da explicação, geramos perturbações e verificamos
       se o modelo mantém a decisão quando apenas essa feature está ativa.
     • Critério: Feature é fiel se >95% das perturbações mantêm a decisão.
     • Objetivo: Garantir que features explicativas CAUSAM a decisão.

  2. NECESSIDADE (Minimality) - Teste Determinístico (Worst-Case)
     • Para cada feature, construímos o cenário mais adverso possível:
       removemos a feature e atribuímos valores extremos às demais features
       não-explicativas (pior caso que maximiza score positivo ou negativo).
     • Critério: Feature é necessária se sua remoção SEMPRE quebra a decisão
       no pior caso deterministicamente possível.
     • Objetivo: Eliminar features redundantes (minimalidade).

  NOTA TÉCNICA: Fidelidade é suficiência estatística (perturbações),
                Necessidade é teste lógico (existe caso adverso).

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
CONFIGURAÇÃO
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Dataset:              Mnist
  Instâncias:           503
  Features:             784
  Perturbações/inst:    500
  Data:                 2026-02-06 08:40:14

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
RESULTADOS
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  MÉTRICAS GLOBAIS:
    Fidelidade:       100.0%
    Necessidade:      0.2%
    Redundância:      99.8%
    Cobertura:        100.0%
    Tamanho médio:    229.3 features

  POR TIPO DE DECISÃO:

  “Necessidade Estrita (Worst-case)”
  “O teste verifica se a feature é necessária sob o pior cenário adversarial possível, não se ela é única explicação possível.”

  Tipo          | Count |  Fidelidade | Necessidade | Redundância
  ────────────────────────────────────────────────────────────────────────
  Positivas     |   198 |      100.0% |        0.0% |      100.0%
  Negativas     |   248 |      100.0% |        0.0% |      100.0%
  Rejeitadas    |    57 |      100.0% |        1.5% |       98.5%

  TAMANHO DAS EXPLICAÇÕES:
    Média:         229.3 features
    Mediana:       206
    Desvio:        86.1
    Intervalo:     [126, 455]
    Compactação:   71% (vs 784 features totais)

3.3 DISTRIBUIÇÃO DE TAMANHOS DAS EXPLICAÇÕES
────────────────────────────────────────────────────────────────────────────────

  Variáveis │ Quantidade │ Porcentagem │ Visualização
  ───────────┼────────────┼─────────────┼──────────────────────────────────────────
       6+    │     503    │    100.0%   │ ██████████████████████████████████████████████████

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
INTERPRETAÇÃO DOS RESULTADOS
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Fidelidade:       100.0%
  Necessidade:      0.2%
  Redundância:      99.8%
  Tamanho médio:    229.3 features
  Cobertura:        100.0%

  AVALIAÇÃO: Explicações fiéis, mas 100% de redundância (features desnecessárias).

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
LIMITAÇÕES OBSERVADAS
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  • Alta redundância (100%): explicações não são minimais.
    Possível causa: threshold de rejeição muito conservador ou
    features correlacionadas no dataset.
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
RECOMENDAÇÕES
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  • Ajustar hiperparâmetros (threshold de rejeição, tolerâncias).
  • Investigar instâncias com baixa fidelidade ou alta redundância.
  • Alta redundância: considerar pós-processamento para remover features
    desnecessárias (ex: backward selection).

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Relatório gerado em: 2026-02-06 08:40:14
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
