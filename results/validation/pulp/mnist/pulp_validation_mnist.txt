╔══════════════════════════════════════════════════════════════════════════════╗
║                                                                              ║
║                     VALIDAÇÃO DE EXPLICABILIDADE - PULP                      ║
║                                    Mnist                                     ║
║                                                                              ║
╚══════════════════════════════════════════════════════════════════════════════╝

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
RESUMO EXECUTIVO
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Dataset:                Mnist
  Instâncias Testadas:    4190
  Features Totais:        784

  MÉTRICAS PRINCIPAIS:
    • Fidelidade:                      100.0%
    • Necessidade (feat. necessárias): 0.5%
    • Tamanho Médio:                   270.7 features
    • Taxa de Rejeição:     8.2% (342 instâncias)

  CONCLUSÃO:
    Explicações fiéis, porém contêm features redundantes.

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
METODOLOGIA DE VALIDAÇÃO
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Método Avaliado:         PULP
  Perturbações/instância:  500

  TESTES APLICADOS:

  1. FIDELIDADE (Sufficiency) - Teste Probabilístico
     • Para cada feature da explicação, geramos perturbações e verificamos
       se o modelo mantém a decisão quando apenas essa feature está ativa.
     • Critério: Feature é fiel se >95% das perturbações mantêm a decisão.
     • Objetivo: Garantir que features explicativas CAUSAM a decisão.

  2. NECESSIDADE (Minimality) - Teste Determinístico (Worst-Case)
     • Para cada feature, construímos o cenário mais adverso possível:
       removemos a feature e atribuímos valores extremos às demais features
       não-explicativas (pior caso que maximiza score positivo ou negativo).
     • Critério: Feature é necessária se sua remoção SEMPRE quebra a decisão
       no pior caso deterministicamente possível.
     • Objetivo: Eliminar features redundantes (minimalidade).

  NOTA TÉCNICA: Fidelidade é suficiência estatística (perturbações),
                Necessidade é teste lógico (existe caso adverso).

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
CONFIGURAÇÃO
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Dataset:              Mnist
  Instâncias:           4190
  Features:             784
  Perturbações/inst:    500
  Data:                 2026-01-30 16:16:34

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
RESULTADOS
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  MÉTRICAS GLOBAIS:
    Fidelidade:       100.0%
    Necessidade:      0.5%
    Redundância:      99.5%
    Cobertura:        100.0%
    Tamanho médio:    270.7 features

  POR TIPO DE DECISÃO:

  “Necessidade Estrita (Worst-case)”
  “O teste verifica se a feature é necessária sob o pior cenário adversarial possível, não se ela é única explicação possível.”

  Tipo          | Count |  Fidelidade | Necessidade | Redundância
  ────────────────────────────────────────────────────────────────────────
  Positivas     |  1886 |      100.0% |        0.4% |       99.6%
  Negativas     |  1962 |      100.0% |        0.4% |       99.6%
  Rejeitadas    |   342 |      100.0% |        2.1% |       97.9%

  TAMANHO DAS EXPLICAÇÕES:
    Média:         270.7 features
    Mediana:       256
    Desvio:        76.2
    Intervalo:     [161, 532]
    Compactação:   65% (vs 784 features totais)

3.3 DISTRIBUIÇÃO DE TAMANHOS DAS EXPLICAÇÕES
────────────────────────────────────────────────────────────────────────────────

  Variáveis │ Quantidade │ Porcentagem │ Visualização
  ───────────┼────────────┼─────────────┼──────────────────────────────────────────
       6+    │    4190    │    100.0%   │ ██████████████████████████████████████████████████

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
INTERPRETAÇÃO DOS RESULTADOS
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Fidelidade:       100.0%
  Necessidade:      0.5%
  Redundância:      99.5%
  Tamanho médio:    270.7 features
  Cobertura:        100.0%

  AVALIAÇÃO: Explicações fiéis, mas 99% de redundância (features desnecessárias).

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
LIMITAÇÕES OBSERVADAS
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  • Alta redundância (99%): explicações não são minimais.
    Possível causa: threshold de rejeição muito conservador ou
    features correlacionadas no dataset.
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
RECOMENDAÇÕES
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  • Ajustar hiperparâmetros (threshold de rejeição, tolerâncias).
  • Investigar instâncias com baixa fidelidade ou alta redundância.
  • Alta redundância: considerar pós-processamento para remover features
    desnecessárias (ex: backward selection).

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Relatório gerado em: 2026-01-30 16:16:34
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
