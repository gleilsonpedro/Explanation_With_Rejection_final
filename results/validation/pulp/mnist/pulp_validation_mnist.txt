╔══════════════════════════════════════════════════════════════════════════════╗
║                                                                              ║
║                     VALIDAÇÃO DE EXPLICABILIDADE - PULP                      ║
║                                    Mnist                                     ║
║                                                                              ║
╚══════════════════════════════════════════════════════════════════════════════╝

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
RESUMO EXECUTIVO
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Dataset:                Mnist
  Instâncias Testadas:    210
  Features Totais:        196

  MÉTRICAS PRINCIPAIS:
    • Fidelidade:                      100.0%
    • Necessidade (feat. necessárias): 1.0%
    • Tamanho Médio:                   53.1 features
    • Taxa de Rejeição:     1.4% (3 instâncias)

  CONCLUSÃO:
    Explicações fiéis, porém contêm features redundantes.

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
METODOLOGIA DE VALIDAÇÃO
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Método Avaliado:         PULP
  Perturbações/instância:  1,000

  TESTES APLICADOS:

  1. FIDELIDADE (Sufficiency) - Teste Probabilístico
     • Para cada feature da explicação, geramos perturbações e verificamos
       se o modelo mantém a decisão quando apenas essa feature está ativa.
     • Critério: Feature é fiel se >95% das perturbações mantêm a decisão.
     • Objetivo: Garantir que features explicativas CAUSAM a decisão.

  2. NECESSIDADE (Minimality) - Teste Determinístico (Worst-Case)
     • Para cada feature, construímos o cenário mais adverso possível:
       removemos a feature e atribuímos valores extremos às demais features
       não-explicativas (pior caso que maximiza score positivo ou negativo).
     • Critério: Feature é necessária se sua remoção SEMPRE quebra a decisão
       no pior caso deterministicamente possível.
     • Objetivo: Eliminar features redundantes (minimalidade).

  NOTA TÉCNICA: Fidelidade é suficiência estatística (perturbações),
                Necessidade é teste lógico (existe caso adverso).

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
CONFIGURAÇÃO
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Dataset:              Mnist
  Instâncias:           210
  Features:             196
  Perturbações/inst:    1,000
  Data:                 2026-01-31 16:33:30

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
RESULTADOS
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  MÉTRICAS GLOBAIS:
    Fidelidade:       100.0%
    Necessidade:      1.0%
    Redundância:      99.0%
    Cobertura:        100.0%
    Tamanho médio:    53.1 features

  POR TIPO DE DECISÃO:

  “Necessidade Estrita (Worst-case)”
  “O teste verifica se a feature é necessária sob o pior cenário adversarial possível, não se ela é única explicação possível.”

  Tipo          | Count |  Fidelidade | Necessidade | Redundância
  ────────────────────────────────────────────────────────────────────────
  Positivas     |    99 |      100.0% |        1.1% |       98.9%
  Negativas     |   108 |      100.0% |        0.5% |       99.5%
  Rejeitadas    |     3 |      100.0% |       15.8% |       84.2%

  TAMANHO DAS EXPLICAÇÕES:
    Média:         53.1 features
    Mediana:       51
    Desvio:        15.5
    Intervalo:     [32, 120]
    Compactação:   73% (vs 196 features totais)

3.3 DISTRIBUIÇÃO DE TAMANHOS DAS EXPLICAÇÕES
────────────────────────────────────────────────────────────────────────────────

  Variáveis │ Quantidade │ Porcentagem │ Visualização
  ───────────┼────────────┼─────────────┼──────────────────────────────────────────
       6+    │     210    │    100.0%   │ ██████████████████████████████████████████████████

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
INTERPRETAÇÃO DOS RESULTADOS
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Fidelidade:       100.0%
  Necessidade:      1.0%
  Redundância:      99.0%
  Tamanho médio:    53.1 features
  Cobertura:        100.0%

  AVALIAÇÃO: Explicações fiéis, mas 99% de redundância (features desnecessárias).

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
LIMITAÇÕES OBSERVADAS
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  • Alta redundância (99%): explicações não são minimais.
    Possível causa: threshold de rejeição muito conservador ou
    features correlacionadas no dataset.
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
RECOMENDAÇÕES
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  • Ajustar hiperparâmetros (threshold de rejeição, tolerâncias).
  • Investigar instâncias com baixa fidelidade ou alta redundância.
  • Alta redundância: considerar pós-processamento para remover features
    desnecessárias (ex: backward selection).

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Relatório gerado em: 2026-01-31 16:33:30
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
