╔══════════════════════════════════════════════════════════════════════════════╗
║                                                                              ║
║                     VALIDAÇÃO DE EXPLICABILIDADE - PULP                      ║
║                            Pima Indians Diabetes                             ║
║                                                                              ║
╚══════════════════════════════════════════════════════════════════════════════╝

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
RESUMO EXECUTIVO
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Dataset:                Pima Indians Diabetes
  Instâncias Testadas:    231
  Features Totais:        8

  MÉTRICAS PRINCIPAIS:
    • Fidelidade:                      100.0%
    • Necessidade (feat. necessárias): 21.0%
    • Tamanho Médio:                   4.2 features
    • Taxa de Rejeição:     1.3% (3 instâncias)

  CONCLUSÃO:
    Explicações fiéis, porém contêm features redundantes.

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
METODOLOGIA DE VALIDAÇÃO
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Método Avaliado:         PULP
  Perturbações/instância:  1,000

  TESTES APLICADOS:

  1. FIDELIDADE (Sufficiency) - Teste Probabilístico
     • Para cada feature da explicação, geramos perturbações e verificamos
       se o modelo mantém a decisão quando apenas essa feature está ativa.
     • Critério: Feature é fiel se >95% das perturbações mantêm a decisão.
     • Objetivo: Garantir que features explicativas CAUSAM a decisão.

  2. NECESSIDADE (Minimality) - Teste Determinístico (Worst-Case)
     • Para cada feature, construímos o cenário mais adverso possível:
       removemos a feature e atribuímos valores extremos às demais features
       não-explicativas (pior caso que maximiza score positivo ou negativo).
     • Critério: Feature é necessária se sua remoção SEMPRE quebra a decisão
       no pior caso deterministicamente possível.
     • Objetivo: Eliminar features redundantes (minimalidade).

  NOTA TÉCNICA: Fidelidade é suficiência estatística (perturbações),
                Necessidade é teste lógico (existe caso adverso).

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
CONFIGURAÇÃO
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Dataset:              Pima Indians Diabetes
  Instâncias:           231
  Features:             8
  Perturbações/inst:    1,000
  Data:                 2026-01-30 16:21:32

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
RESULTADOS
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  MÉTRICAS GLOBAIS:
    Fidelidade:       100.0%
    Necessidade:      21.0%
    Redundância:      79.0%
    Cobertura:        100.0%
    Tamanho médio:    4.2 features

  POR TIPO DE DECISÃO:

  “Necessidade Estrita (Worst-case)”
  “O teste verifica se a feature é necessária sob o pior cenário adversarial possível, não se ela é única explicação possível.”

  Tipo          | Count |  Fidelidade | Necessidade | Redundância
  ────────────────────────────────────────────────────────────────────────
  Positivas     |    59 |      100.0% |       67.2% |       32.8%
  Negativas     |   169 |      100.0% |        3.6% |       96.4%
  Rejeitadas    |     3 |      100.0% |       91.7% |        8.3%

  TAMANHO DAS EXPLICAÇÕES:
    Média:         4.2 features
    Mediana:       4
    Desvio:        1.3
    Intervalo:     [2, 8]
    Compactação:   47% (vs 8 features totais)

3.3 DISTRIBUIÇÃO DE TAMANHOS DAS EXPLICAÇÕES
────────────────────────────────────────────────────────────────────────────────

  Variáveis │ Quantidade │ Porcentagem │ Visualização
  ───────────┼────────────┼─────────────┼──────────────────────────────────────────
        2    │      13    │      5.6%   │ ██                                      
        3    │      55    │     23.8%   │ ███████████                             
        4    │      81    │     35.1%   │ █████████████████                       
        5    │      48    │     20.8%   │ ██████████                              
       6+    │      34    │     14.7%   │ ███████                                 

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
INTERPRETAÇÃO DOS RESULTADOS
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  Fidelidade:       100.0%
  Necessidade:      21.0%
  Redundância:      79.0%
  Tamanho médio:    4.2 features
  Cobertura:        100.0%

  AVALIAÇÃO: Explicações fiéis, mas 79% de redundância (features desnecessárias).

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
LIMITAÇÕES OBSERVADAS
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  • Alta redundância (79%): explicações não são minimais.
    Possível causa: threshold de rejeição muito conservador ou
    features correlacionadas no dataset.
  • Explicações usam 4.2 de 8 features (53%):
    Compactação insuficiente para interpretabilidade prática.
  • Explicações completas detectadas (max=8 features):
    Método falhou em reduzir dimensionalidade em alguns casos.
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
RECOMENDAÇÕES
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

  • Ajustar hiperparâmetros (threshold de rejeição, tolerâncias).
  • Investigar instâncias com baixa fidelidade ou alta redundância.
  • Alta redundância: considerar pós-processamento para remover features
    desnecessárias (ex: backward selection).

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Relatório gerado em: 2026-01-30 16:21:32
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
