# CorreÃ§Ã£o do Bug de subsample_size âœ…

## ğŸ”´ Problema Identificado

O `subsample_size` estava sendo aplicado **ANTES** da divisÃ£o treino/teste, resultando em:

### Exemplo: creditcard com subsample_size=0.02 (2%)

**ANTES (ERRADO):**
```
1. Dataset: 284,807 instÃ¢ncias
2. Subsample (2%): 5,696 instÃ¢ncias  âŒ
3. Split 70/30: 
   - Treino: 3,987 instÃ¢ncias (1.4% do original)  âŒ
   - Teste: 1,709 instÃ¢ncias (0.6% do original)
```

**DEPOIS (CORRETO):**
```
1. Dataset: 284,807 instÃ¢ncias
2. Split 70/30: 
   - Treino: 199,364 instÃ¢ncias (70% do original)  âœ…
   - Teste: 85,443 instÃ¢ncias (30% do original)
3. Subsample apenas no teste (2%): 1,708 instÃ¢ncias  âœ…
```

### Impacto

- **Treino:** +195,377 instÃ¢ncias (+4900%!) ğŸš€
- **Qualidade do modelo:** MUITO MELHOR (treina com dataset completo)
- **Tempo de explicaÃ§Ãµes:** MESMA (teste subsampled)

## âœ… CorreÃ§Ãµes Implementadas

### 1. [peab.py](../peab.py)

**Adicionada funÃ§Ã£o para subsample apenas no teste:**
```python
def aplicar_subsample_teste(X_test, y_test, subsample_size):
    """Aplica subsample APENAS no conjunto de teste."""
    if subsample_size and subsample_size < 1.0:
        idx = np.arange(len(y_test))
        sample_idx, _ = train_test_split(
            idx, 
            test_size=(1 - subsample_size), 
            random_state=RANDOM_STATE, 
            stratify=y_test
        )
        X_test = X_test.iloc[sample_idx]
        y_test = y_test.iloc[sample_idx]
        print(f"[SUBSAMPLE] Teste reduzido para {len(y_test)} instÃ¢ncias")
    return X_test, y_test
```

**Removido subsample de `configurar_experimento()`:**
```python
def configurar_experimento(dataset_name):
    X, y, nomes_classes = carregar_dataset(dataset_name)
    cfg = DATASET_CONFIG.get(dataset_name, {...})
    
    # âœ… REMOVIDO: subsample nÃ£o Ã© mais aplicado aqui
    # O dataset completo Ã© retornado para treino
    
    return X, y, nomes_classes, cfg['rejection_cost'], cfg['test_size']
```

**Aplicado subsample apÃ³s o split:**
```python
def executar_experimento_para_dataset(dataset_name):
    # ...
    X_train, X_test, y_train, y_test = train_test_split(
        X_full, y_full, test_size=test_size, ...
    )
    
    # âœ… Subsample aplicado DEPOIS do split
    cfg = DATASET_CONFIG.get(dataset_name, {})
    subsample_size = cfg.get('subsample_size', None)
    if subsample_size:
        X_test, y_test = aplicar_subsample_teste(X_test, y_test, subsample_size)
```

### 2. [shared_training.py](../utils/shared_training.py)

Aplicada mesma correÃ§Ã£o para MinExp, PuLP e Anchor:

```python
def get_shared_pipeline(dataset_name):
    # ...
    # Split treino/teste
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, ...
    )
    
    # âœ… Subsample aplicado DEPOIS do split
    cfg = DATASET_CONFIG.get(dataset_name, {})
    subsample_size = cfg.get('subsample_size', None)
    if subsample_size:
        from peab import aplicar_subsample_teste
        X_test, y_test = aplicar_subsample_teste(X_test, y_test, subsample_size)
    
    # Treinar modelo (usa X_train COMPLETO)
    pipeline, t_plus, t_minus, model_params = treinar_e_avaliar_modelo(
        X_train=X_train, ...  # âœ… Treino com dataset completo
    )
```

## ğŸ“Š Datasets Afetados

Datasets com `subsample_size` configurado:
- **creditcard:** 0.02 (2%) - Impacto ENORME (+4900% dados de treino)
- **covertype:** 0.01 (1%) - Impacto ENORME (+9900% dados de treino)
- **mnist:** 0.12 (12%) - Para variaÃ§Ãµes 3vs8, 1vs2, etc

## ğŸ¯ BenefÃ­cios

1. **Modelo melhor treinado:** Usa 70% do dataset original (ao invÃ©s de 1.4%)
2. **Thresholds mais confiÃ¡veis:** Otimizados com mais dados
3. **Resultados mais robustos:** ExplicaÃ§Ãµes baseadas em modelo de alta qualidade
4. **Tempo mantido:** ExplicaÃ§Ãµes ainda sÃ£o rÃ¡pidas (teste subsampled)

## ğŸ”§ O Que Fazer Agora

### IMPORTANTE: Reprocessar experimentos com subsample

Os experimentos jÃ¡ executados com `subsample_size` devem ser **refeitos**:

```bash
# Datasets afetados que precisam ser reprocessados:
python peab.py      # Escolher: creditcard
python minexp.py    # Escolher: creditcard
python pulp.py      # Escolher: creditcard (se existir)
python anchor.py    # Escolher: creditcard (se existir)

# Repetir para covertype e mnist (se aplicÃ¡vel)
```

### Verificar resultados antigos

Os resultados antigos em `json/*/creditcard.json` e `json/*/covertype.json` foram treinados com **apenas 1-2% dos dados**! âš ï¸

Compare:
- **Antes:** Accuracy ~85-90% (modelo fraco)
- **Depois:** Accuracy ~95-98% (modelo forte)

## âœ… Teste de ValidaÃ§Ã£o

Execute o teste para confirmar a correÃ§Ã£o:

```bash
python temporarios/testar_correcao_subsample.py
```

**SaÃ­da esperada:**
```
COMPARAÃ‡ÃƒO FINAL
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                         | ANTIGO (ERRADO)  | CORRIGIDO
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
InstÃ¢ncias de TREINO     |      3,987       |   199,364    âœ…
InstÃ¢ncias de TESTE      |      1,709       |    1,708
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

## ğŸ“ Notas TÃ©cnicas

### Por que subsample apenas no teste?

1. **Treino:** Precisa de TODOS os dados para aprender padrÃµes
2. **Teste:** Subsampled apenas para acelerar geraÃ§Ã£o de explicaÃ§Ãµes
3. **ValidaÃ§Ã£o:** Ainda funciona corretamente (mÃ©tricas no teste subsampled)

### EstratificaÃ§Ã£o mantida

O subsample usa `stratify=y_test` para manter proporÃ§Ã£o de classes:
```python
sample_idx, _ = train_test_split(
    idx, 
    test_size=(1 - subsample_size), 
    random_state=RANDOM_STATE, 
    stratify=y_test  # âœ… MantÃ©m balanceamento
)
```

---

**Data da correÃ§Ã£o:** 6 de fevereiro de 2026  
**Arquivos modificados:**
- `peab.py` (linhas 330-350, 410-440)
- `utils/shared_training.py` (linhas 65-75)
