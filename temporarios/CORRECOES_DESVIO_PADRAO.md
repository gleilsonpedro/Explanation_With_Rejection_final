# Corre√ß√µes para Gerar Desvio Padr√£o nas Tabelas de Runtime

## üìã Resumo das Corre√ß√µes

### Problema Identificado
Os scripts **Anchor** e **MinExp** n√£o estavam salvando o tempo de execu√ß√£o individual (`computation_time`) para cada inst√¢ncia no JSON, impossibilitando o c√°lculo do desvio padr√£o.

### ‚úÖ Corre√ß√µes Implementadas

#### 1. **anchor.py** (3 altera√ß√µes)
- **Linha ~189**: Adicionado dicion√°rio `tempos_individuais = {}` para armazenar tempo por inst√¢ncia
- **Linha ~259**: Adicionado `tempos_individuais[i] = runtime` para salvar tempo de cada inst√¢ncia
- **Linha ~690**: Adicionado `'computation_time': float(tempos_ind_local.get(i, 0.0))` no `per_instance`

**Resultado**: Anchor agora salva o tempo de cada inst√¢ncia no JSON.

#### 2. **minexp.py** (2 altera√ß√µes)
- **Linha ~392**: Renomeado `'tempo_segundos'` para `'computation_time'` (consist√™ncia)
- **Linha ~737**: Renomeado `'tempo_segundos'` para `'computation_time'` (consist√™ncia)

**Resultado**: MinExp agora usa o mesmo campo que PEAB e Anchor.

#### 3. **temporarios/gerar_tabela_runtime_unificada.py** (1 altera√ß√£o)
- Removido fallback `or inst.get("tempo_segundos")` j√° que agora todos usam `computation_time`

**Resultado**: Script simplificado e consistente.

---

## üîÑ Plano de Re-execu√ß√£o

### Datasets que Precisam Ser Re-executados

#### ‚úÖ Alta Prioridade (para tabela principal)
1. **Banknote** - R√°pido (~1 min)
2. **Vertebral Column** - R√°pido (~1 min)
3. **Pima Indians** - R√°pido (~2 min)
4. **Heart Disease** - R√°pido (~1 min)
5. **Breast Cancer** - M√©dio (~5 min)
6. **Sonar** - M√©dio (~10 min)
7. **Spambase** - M√©dio (~5 min)

#### ‚ö†Ô∏è Datasets Demorados (opcional, pode rodar depois)
8. **Credit Card** - Anchor lento (~30 min)
9. **Covertype** - Anchor muito lento (~2-3 horas)
10. **MNIST (3 vs 8)** - Anchor extremamente lento (~5-8 horas)

---

## üìù Comandos para Re-execu√ß√£o

### 1. PEAB (MINABRO) - TODOS OS DATASETS
```bash
# Datasets r√°pidos (7-10 min total)
python peab.py --dataset banknote
python peab.py --dataset vertebral_column
python peab.py --dataset pima_indians_diabetes
python peab.py --dataset heart_disease
python peab.py --dataset breast_cancer
python peab.py --dataset sonar
python peab.py --dataset spambase

# Datasets demorados (1-2 horas total)
python peab.py --dataset creditcard
python peab.py --dataset covertype
python peab.py --dataset mnist
```

### 2. Anchor - PRIORIZAR R√ÅPIDOS
```bash
# PRIORIDADE 1: Datasets r√°pidos (15-30 min total)
python anchor.py --dataset banknote
python anchor.py --dataset vertebral_column
python anchor.py --dataset pima_indians_diabetes
python anchor.py --dataset heart_disease
python anchor.py --dataset breast_cancer
python anchor.py --dataset sonar
python anchor.py --dataset spambase

# PRIORIDADE 2: Datasets demorados (RODAR SEPARADAMENTE, DE PREFER√äNCIA √Ä NOITE)
# python anchor.py --dataset creditcard        # ~30 min
# python anchor.py --dataset covertype         # ~2-3 horas
# python anchor.py --dataset mnist             # ~5-8 horas (!)
```

### 3. MinExp (AbLinRO) - TODOS OS DATASETS
```bash
# Datasets r√°pidos (10-15 min total)
python minexp.py --dataset banknote
python minexp.py --dataset vertebral_column
python minexp.py --dataset pima_indians_diabetes
python minexp.py --dataset heart_disease
python minexp.py --dataset breast_cancer
python minexp.py --dataset sonar
python minexp.py --dataset spambase

# Datasets demorados (2-3 horas total)
python minexp.py --dataset creditcard
python minexp.py --dataset covertype
python minexp.py --dataset mnist
```

---

## üöÄ Estrat√©gia de Execu√ß√£o Recomendada

### Op√ß√£o 1: Tabela R√°pida (Apenas Datasets Comuns - 7 datasets)
**Tempo Total: ~1-2 horas**

1. Re-executar PEAB, Anchor e MinExp para os 7 datasets r√°pidos
2. Gerar tabela com valores atualizados e desvio padr√£o
3. Deixar Credit Card, Covertype e MNIST para depois

```bash
# Executar em sequ√™ncia (ou em paralelo se tiver GPU/CPU suficiente)
for dataset in banknote vertebral_column pima_indians_diabetes heart_disease breast_cancer sonar spambase; do
    echo "Processando $dataset..."
    python peab.py --dataset $dataset
    python anchor.py --dataset $dataset
    python minexp.py --dataset $dataset
done

# Gerar tabela
python temporarios/gerar_tabela_runtime_unificada.py
```

### Op√ß√£o 2: Tabela Completa (10 datasets)
**Tempo Total: ~10-15 horas (deixar rodando overnight)**

1. Re-executar todos os datasets
2. Priorizar PEAB e MinExp (mais r√°pidos)
3. Deixar Anchor (creditcard, covertype, mnist) rodando √† noite

```bash
# Dia 1: PEAB e MinExp (todos) + Anchor (r√°pidos)
python peab.py --dataset banknote
python peab.py --dataset vertebral_column
# ... (todos os datasets PEAB)

python minexp.py --dataset banknote
# ... (todos os datasets MinExp)

python anchor.py --dataset banknote
# ... (apenas datasets r√°pidos Anchor)

# Dia 2 (overnight): Anchor (demorados)
python anchor.py --dataset creditcard
python anchor.py --dataset covertype
python anchor.py --dataset mnist

# Gerar tabela final
python temporarios/gerar_tabela_runtime_unificada.py
```

---

## ‚ú® Resultado Esperado

Ap√≥s re-executar os scripts, os JSONs ter√£o:

```json
{
  "per_instance": [
    {
      "id": "0",
      "y_true": 0,
      "y_pred": 0,
      "rejected": false,
      "decision_score": -0.443,
      "explanation": ["feature1", "feature2"],
      "explanation_size": 2,
      "computation_time": 0.00123  // ‚Üê AGORA TODOS T√äM ISSO!
    },
    ...
  ],
  "computation_time": {
    "total": 25.5,
    "mean_per_instance": 0.062,
    "positive": 0.055,
    "negative": 0.048,
    "rejected": 0.089
  }
}
```

A tabela final ter√° desvio padr√£o:

```latex
Banknote & 5.6 $\pm$ 1.2 & 40.8 $\pm$ 5.3 & ...
```

---

## üìä Verifica√ß√£o R√°pida

Ap√≥s re-executar um dataset, verifique se o JSON tem `computation_time` por inst√¢ncia:

```bash
python -c "import json; d=json.load(open('json/anchor/banknote.json')); print('Has per_instance:', 'per_instance' in d); print('Has computation_time:', 'computation_time' in d.get('per_instance', [{}])[0] if d.get('per_instance') else False)"
```

**Esperado**: `Has per_instance: True` e `Has computation_time: True`

---

## üéØ Pr√≥ximos Passos

1. ‚úÖ Escolher estrat√©gia (Op√ß√£o 1 ou 2)
2. ‚úÖ Re-executar scripts conforme escolha
3. ‚úÖ Executar `temporarios/gerar_tabela_runtime_unificada.py`
4. ‚úÖ Verificar tabela gerada em `results/tabelas_latex/runtime_unified_with_std.tex`
5. ‚úÖ Copiar tabela LaTeX para artigo

---

**Data**: 7 de fevereiro de 2026
**Status**: Corre√ß√µes implementadas, pronto para re-execu√ß√£o
